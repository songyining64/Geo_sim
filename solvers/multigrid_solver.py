"""
å¢å¼ºå‹å¤šé‡ç½‘æ ¼æ±‚è§£å™¨å®ç°

åŒ…å«ä»¥ä¸‹å¢å¼ºåŠŸèƒ½ï¼š
1. å¤šé‡ç½‘æ ¼æ±‚è§£å™¨çš„å®Œå–„
   - ç½‘æ ¼ç²—åŒ–ç­–ç•¥ï¼šåŸºäºå‡ ä½•æˆ–ä»£æ•°çš„è‡ªé€‚åº”ç²—åŒ–
   - å¾ªç¯ç­–ç•¥æ‰©å±•ï¼šVå¾ªç¯ã€Wå¾ªç¯ã€FMGç­‰
   - å¹³æ»‘å™¨ä¼˜åŒ–ï¼šJacobiã€Gauss-Seidelã€Chebyshevç­‰
   - å¹¶è¡ŒåŒ–æ”¯æŒï¼šåˆ†å¸ƒå¼å†…å­˜ä¸‹çš„å¤šé‡ç½‘æ ¼

2. å¤šç‰©ç†åœºè€¦åˆæ±‚è§£
   - è€¦åˆæ–¹ç¨‹ç»„ç»„è£…
   - åˆ†åŒºæ±‚è§£ç­–ç•¥
   - æ—¶é—´ç§¯åˆ†å™¨æ”¯æŒ
"""

import numpy as np
import scipy.sparse as sp
from typing import Dict, List, Tuple, Optional, Union, Any, Callable
from dataclasses import dataclass
from abc import ABC, abstractmethod
import warnings
import time
from scipy.sparse.linalg import spsolve, cg, gmres
from scipy.linalg import solve_triangular


@dataclass
class MultigridConfig:
    """å¢å¼ºå‹å¤šé‡ç½‘æ ¼é…ç½®"""
    max_levels: int = 10  # æœ€å¤§å±‚æ•°
    coarse_solver: str = 'direct'  # ç²—ç½‘æ ¼æ±‚è§£å™¨ç±»å‹
    smoother: str = 'jacobi'  # å¹³æ»‘å™¨ç±»å‹
    pre_smoothing_steps: int = 2  # é¢„å¹³æ»‘æ­¥æ•°
    post_smoothing_steps: int = 2  # åå¹³æ»‘æ­¥æ•°
    tolerance: float = 1e-8  # æ”¶æ•›å®¹å·®
    max_iterations: int = 100  # æœ€å¤§è¿­ä»£æ¬¡æ•°
    cycle_type: str = 'v'  # å¾ªç¯ç±»å‹ï¼š'v', 'w', 'fmg'
    
    # æ–°å¢é…ç½®é€‰é¡¹
    adaptive_coarsening: bool = True  # è‡ªé€‚åº”ç²—åŒ–
    strong_threshold: float = 0.25  # å¼ºè¿æ¥é˜ˆå€¼
    max_coarse_size: int = 100  # æœ€å¤§ç²—ç½‘æ ¼å¤§å°
    parallel_support: bool = False  # å¹¶è¡Œæ”¯æŒ
    chebyshev_degree: int = 4  # Chebyshevå¤šé¡¹å¼æ¬¡æ•°
    relaxation_factor: float = 1.0  # æ¾å¼›å› å­


class AdvancedSmoother:
    """é«˜çº§å¹³æ»‘å™¨é›†åˆ"""
    
    @staticmethod
    def jacobi_smooth(A: sp.spmatrix, b: np.ndarray, x: np.ndarray, 
                      omega: float = 1.0, iterations: int = 1) -> np.ndarray:
        """Jacobiå¹³æ»‘å™¨ï¼ˆå¸¦æ¾å¼›å› å­ï¼‰"""
        D = sp.diags(A.diagonal())
        D_inv = sp.diags(1.0 / A.diagonal())
        L_plus_U = A - D
        
        x_new = x.copy()
        for _ in range(iterations):
            x_new = x_new + omega * D_inv @ (b - A @ x_new)
        
        return x_new
    
    @staticmethod
    def gauss_seidel_smooth(A: sp.spmatrix, b: np.ndarray, x: np.ndarray, 
                           iterations: int = 1) -> np.ndarray:
        """Gauss-Seidelå¹³æ»‘å™¨"""
        A_dense = A.toarray()
        x_new = x.copy()
        
        for _ in range(iterations):
            for i in range(len(x)):
                x_new[i] = (b[i] - np.dot(A_dense[i, :i], x_new[:i]) - 
                           np.dot(A_dense[i, i+1:], x_new[i+1:])) / A_dense[i, i]
        
        return x_new
    
    @staticmethod
    def chebyshev_smooth(A: sp.spmatrix, b: np.ndarray, x: np.ndarray, 
                        degree: int = 4, iterations: int = 1) -> np.ndarray:
        """Chebyshevå¤šé¡¹å¼å¹³æ»‘å™¨"""
        # ä¼°è®¡ç‰¹å¾å€¼èŒƒå›´
        D = sp.diags(A.diagonal())
        D_inv = sp.diags(1.0 / A.diagonal())
        B = D_inv @ A
        
        # ä½¿ç”¨å¹‚è¿­ä»£ä¼°è®¡æœ€å¤§ç‰¹å¾å€¼
        v = np.random.randn(len(x))
        v = v / np.linalg.norm(v)
        
        for _ in range(10):
            v = B @ v
            v = v / np.linalg.norm(v)
        
        lambda_max = np.dot(v, B @ v)
        lambda_min = 1.0  # å‡è®¾æœ€å°ç‰¹å¾å€¼ä¸º1
        
        # Chebyshevå¤šé¡¹å¼å‚æ•°
        alpha = (lambda_max + lambda_min) / 2
        beta = (lambda_max - lambda_min) / 2
        
        x_new = x.copy()
        for _ in range(iterations):
            # åº”ç”¨Chebyshevå¤šé¡¹å¼
            r = b - A @ x_new
            p = D_inv @ r
            q = p
            
            for k in range(1, degree + 1):
                if k == 1:
                    x_new = x_new + (2.0 / alpha) * p
                else:
                    gamma = 2.0 / (alpha - beta * np.cos(np.pi * (2*k-1) / (2*degree)))
                    p_new = gamma * (D_inv @ (b - A @ x_new)) - (gamma - 1) * p
                    x_new = x_new + gamma * p_new
                    p = p_new
        
        return x_new
    
    @staticmethod
    def symmetric_gauss_seidel_smooth(A: sp.spmatrix, b: np.ndarray, x: np.ndarray, 
                                    iterations: int = 1) -> np.ndarray:
        """å¯¹ç§°Gauss-Seidelå¹³æ»‘å™¨"""
        A_dense = A.toarray()
        x_new = x.copy()
        
        for _ in range(iterations):
            # å‰å‘æ‰«æ
            for i in range(len(x)):
                x_new[i] = (b[i] - np.dot(A_dense[i, :i], x_new[:i]) - 
                           np.dot(A_dense[i, i+1:], x_new[i+1:])) / A_dense[i, i]
            
            # åå‘æ‰«æ
            for i in range(len(x)-1, -1, -1):
                x_new[i] = (b[i] - np.dot(A_dense[i, :i], x_new[:i]) - 
                           np.dot(A_dense[i, i+1:], x_new[i+1:])) / A_dense[i, i]
        
        return x_new


class AdaptiveCoarsening:
    """è‡ªé€‚åº”ç²—åŒ–ç­–ç•¥"""
    
    @staticmethod
    def algebraic_coarsening(A: sp.spmatrix, strong_threshold: float = 0.25) -> Tuple[List[int], List[int]]:
        """ä»£æ•°ç²—åŒ–ç­–ç•¥ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        n = A.shape[0]
        
        # è®¡ç®—å¼ºè¿æ¥çŸ©é˜µ
        S = sp.lil_matrix((n, n))
        for i in range(n):
            row = A[i].toarray().flatten()
            diag = A[i, i]
            
            for j in range(n):
                if i != j and abs(row[j]) > strong_threshold * abs(diag):
                    S[i, j] = 1
        
        # ä½¿ç”¨æ”¹è¿›çš„æœ€å¤§ç‹¬ç«‹é›†ç®—æ³•
        coarse_points = []
        fine_points = []
        marked = np.zeros(n, dtype=bool)
        
        # ç¬¬ä¸€éï¼šé€‰æ‹©åº¦æ•°æœ€å¤§çš„ç‚¹
        degrees = np.array(S.sum(axis=1)).flatten()
        
        while np.any(~marked):
            unmarked = np.where(~marked)[0]
            if len(unmarked) == 0:
                break
            
            # é€‰æ‹©æœªæ ‡è®°çš„åº¦æ•°æœ€å¤§çš„ç‚¹
            max_degree_idx = unmarked[np.argmax(degrees[unmarked])]
            coarse_points.append(max_degree_idx)
            marked[max_degree_idx] = True
            
            # æ ‡è®°ç›¸é‚»ç‚¹
            neighbors = S[max_degree_idx].nonzero()[1]
            marked[neighbors] = True
        
        # ç¬¬äºŒéï¼šå¤„ç†å‰©ä½™ç‚¹
        for i in range(n):
            if not marked[i]:
                fine_points.append(i)
        
        return coarse_points, fine_points
    
    @staticmethod
    def geometric_coarsening(mesh: Dict, target_size: int) -> Dict:
        """å‡ ä½•ç²—åŒ–ç­–ç•¥ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        nodes = mesh.get('nodes', [])
        elements = mesh.get('elements', [])
        
        if len(nodes) <= target_size:
            return mesh
        
        # ä½¿ç”¨æ›´æ™ºèƒ½çš„ç²—åŒ–ç­–ç•¥
        # 1. è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„è´¨é‡æŒ‡æ ‡
        node_quality = np.zeros(len(nodes))
        for element in elements:
            element_nodes = element.get('nodes', [])
            if len(element_nodes) >= 3:
                # è®¡ç®—å…ƒç´ è´¨é‡ï¼ˆåŸºäºå½¢çŠ¶ï¼‰
                quality = AdaptiveCoarsening._compute_element_quality(nodes, element_nodes)
                for node_id in element_nodes:
                    node_quality[node_id] += quality
        
        # 2. é€‰æ‹©è´¨é‡æœ€é«˜çš„ç‚¹ä½œä¸ºç²—ç½‘æ ¼ç‚¹
        sorted_indices = np.argsort(node_quality)[::-1]
        coarse_size = min(target_size, len(nodes) // 2)
        coarse_indices = sorted_indices[:coarse_size]
        
        # 3. æ„å»ºç²—ç½‘æ ¼
        coarse_nodes = [nodes[i] for i in coarse_indices]
        coarse_elements = []
        
        # é‡æ–°ç¼–å·
        node_mapping = {old: new for new, old in enumerate(coarse_indices)}
        
        for element in elements:
            element_nodes = element.get('nodes', [])
            coarse_element_nodes = []
            
            for node in element_nodes:
                if node in node_mapping:
                    coarse_element_nodes.append(node_mapping[node])
            
            if len(coarse_element_nodes) >= 3:
                coarse_elements.append({'nodes': coarse_element_nodes})
        
        return {
            'nodes': coarse_nodes,
            'elements': coarse_elements,
            'node_mapping': node_mapping
        }
    
    @staticmethod
    def _compute_element_quality(nodes: List, element_nodes: List) -> float:
        """è®¡ç®—å…ƒç´ è´¨é‡"""
        if len(element_nodes) < 3:
            return 0.0
        
        # ç®€åŒ–çš„è´¨é‡è®¡ç®—ï¼šåŸºäºè¾¹é•¿
        coords = [nodes[i] for i in element_nodes]
        min_edge_length = float('inf')
        max_edge_length = 0.0
        
        for i in range(len(coords)):
            for j in range(i+1, len(coords)):
                edge_length = np.linalg.norm(np.array(coords[i]) - np.array(coords[j]))
                min_edge_length = min(min_edge_length, edge_length)
                max_edge_length = max(max_edge_length, edge_length)
        
        if max_edge_length > 0:
            return min_edge_length / max_edge_length
        else:
            return 0.0


class BaseMultigridSolver(ABC):
    """å¢å¼ºå‹å¤šé‡ç½‘æ ¼æ±‚è§£å™¨åŸºç±»"""
    
    def __init__(self, config: MultigridConfig = None):
        self.config = config or MultigridConfig()
        self.levels = []
        self.is_setup = False
        self.smoother = AdvancedSmoother()
        self.coarsening = AdaptiveCoarsening()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'setup_time': 0.0,
            'solve_time': 0.0,
            'total_iterations': 0,
            'final_residual': 0.0
        }
    
    @abstractmethod
    def setup(self, A: sp.spmatrix, b: np.ndarray, **kwargs) -> None:
        """è®¾ç½®å¤šé‡ç½‘æ ¼å±‚æ¬¡"""
        pass
    
    @abstractmethod
    def solve(self, A: sp.spmatrix, b: np.ndarray, x0: np.ndarray = None) -> np.ndarray:
        """æ±‚è§£çº¿æ€§ç³»ç»Ÿ"""
        pass
    
    def v_cycle(self, level: int, b: np.ndarray, x: np.ndarray) -> np.ndarray:
        """V-cycleç®—æ³•"""
        return self._cycle(level, b, x, 'v')
    
    def w_cycle(self, level: int, b: np.ndarray, x: np.ndarray) -> np.ndarray:
        """W-cycleç®—æ³•"""
        return self._cycle(level, b, x, 'w')
    
    def fmg_cycle(self, level: int, b: np.ndarray, x: np.ndarray) -> np.ndarray:
        """FMGï¼ˆå®Œå…¨å¤šé‡ç½‘æ ¼ï¼‰ç®—æ³•"""
        return self._cycle(level, b, x, 'fmg')
    
    def _cycle(self, level: int, b: np.ndarray, x: np.ndarray, cycle_type: str) -> np.ndarray:
        """é€šç”¨å¾ªç¯ç®—æ³•"""
        if level >= len(self.levels) - 1:
            # æœ€ç²—å±‚ï¼šç›´æ¥æ±‚è§£
            A_coarse = self.levels[level]['matrix']
            x_coarse = self._solve_coarse_system(A_coarse, b)
            return x_coarse
        
        A = self.levels[level]['matrix']
        
        # é¢„å¹³æ»‘
        for _ in range(self.config.pre_smoothing_steps):
            x = self._smooth(A, b, x)
        
        # è®¡ç®—æ®‹å·®
        residual = b - A @ x
        
        # é™åˆ¶åˆ°ç²—ç½‘æ ¼
        if level < len(self.restriction_operators):
            R = self.restriction_operators[level]
            coarse_residual = R @ residual
            
            # åœ¨ç²—ç½‘æ ¼ä¸Šæ±‚è§£
            if cycle_type == 'v':
                coarse_error = self.v_cycle(level + 1, coarse_residual, np.zeros_like(coarse_residual))
            elif cycle_type == 'w':
                coarse_error = self.w_cycle(level + 1, coarse_residual, np.zeros_like(coarse_residual))
                coarse_error = self.w_cycle(level + 1, coarse_residual, coarse_error)
            elif cycle_type == 'fmg':
                # FMGï¼šåœ¨ç²—ç½‘æ ¼ä¸Šæ±‚è§£å®Œæ•´é—®é¢˜
                if level == 0:
                    # æœ€ç»†å±‚ï¼šä½¿ç”¨æ’å€¼è§£ä½œä¸ºåˆå€¼
                    coarse_b = coarse_residual
                    coarse_x0 = np.zeros_like(coarse_b)
                else:
                    coarse_b = coarse_residual
                    coarse_x0 = np.zeros_like(coarse_b)
                
                coarse_error = self.fmg_cycle(level + 1, coarse_b, coarse_x0)
            
            # æ’å€¼å›ç»†ç½‘æ ¼
            P = self.interpolation_operators[level]
            error = P @ coarse_error
            
            # ä¿®æ­£è§£
            x = x + error
        
        # åå¹³æ»‘
        for _ in range(self.config.post_smoothing_steps):
            x = self._smooth(A, b, x)
        
        return x
    
    def _smooth(self, A: sp.spmatrix, b: np.ndarray, x: np.ndarray) -> np.ndarray:
        """é«˜çº§å¹³æ»‘å™¨"""
        if self.config.smoother == 'jacobi':
            return self.smoother.jacobi_smooth(A, b, x, 
                                             omega=self.config.relaxation_factor)
        elif self.config.smoother == 'gauss_seidel':
            return self.smoother.gauss_seidel_smooth(A, b, x)
        elif self.config.smoother == 'chebyshev':
            return self.smoother.chebyshev_smooth(A, b, x, 
                                                degree=self.config.chebyshev_degree)
        elif self.config.smoother == 'symmetric_gauss_seidel':
            return self.smoother.symmetric_gauss_seidel_smooth(A, b, x)
        else:
            return self.smoother.jacobi_smooth(A, b, x)
    
    def _solve_coarse_system(self, A: sp.spmatrix, b: np.ndarray) -> np.ndarray:
        """æ±‚è§£ç²—ç½‘æ ¼ç³»ç»Ÿ"""
        if self.config.coarse_solver == 'direct':
            return spsolve(A, b)
        elif self.config.coarse_solver == 'cg':
            return cg(A, b, tol=1e-10)[0]
        elif self.config.coarse_solver == 'gmres':
            return gmres(A, b, tol=1e-10)[0]
        else:
            return spsolve(A, b)
    
    def get_performance_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        return self.performance_stats.copy()


class AlgebraicMultigridSolver(BaseMultigridSolver):
    """å¢å¼ºå‹ä»£æ•°å¤šé‡ç½‘æ ¼æ±‚è§£å™¨"""
    
    def __init__(self, config: MultigridConfig = None):
        super().__init__(config)
        self.interpolation_operators = []
        self.restriction_operators = []
        self.coarse_matrices = []
    
    def setup(self, A: sp.spmatrix, b: np.ndarray, **kwargs) -> None:
        """è®¾ç½®AMGå±‚æ¬¡ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        start_time = time.time()
        print("ğŸ”„ è®¾ç½®å¢å¼ºå‹ä»£æ•°å¤šé‡ç½‘æ ¼...")
        
        self.levels = []
        self.interpolation_operators = []
        self.restriction_operators = []
        self.coarse_matrices = []
        
        current_A = A.copy()
        current_level = 0
        
        while (current_level < self.config.max_levels and 
               current_A.shape[0] > self.config.max_coarse_size):
            
            # åˆ›å»ºå½“å‰å±‚æ¬¡
            level_data = {
                'matrix': current_A,
                'size': current_A.shape[0],
                'level': current_level
            }
            self.levels.append(level_data)
            
            # è‡ªé€‚åº”ç²—åŒ–
            if self.config.adaptive_coarsening:
                coarse_points, fine_points = self.coarsening.algebraic_coarsening(
                    current_A, self.config.strong_threshold
                )
            else:
                # ä½¿ç”¨ç®€å•çš„ç²—åŒ–ç­–ç•¥
                coarse_points = list(range(0, current_A.shape[0], 2))
                fine_points = list(range(1, current_A.shape[0], 2))
            
            # æ„å»ºæ’å€¼ç®—å­
            P = self._build_advanced_interpolation_operator(current_A, coarse_points, fine_points)
            R = P.T  # é™åˆ¶ç®—å­ä¸ºæ’å€¼ç®—å­çš„è½¬ç½®
            
            # è®¡ç®—ç²—ç½‘æ ¼çŸ©é˜µ
            coarse_A = R @ current_A @ P
            
            # å­˜å‚¨ç®—å­
            self.interpolation_operators.append(P)
            self.restriction_operators.append(R)
            self.coarse_matrices.append(coarse_A)
            
            # æ›´æ–°åˆ°ä¸‹ä¸€å±‚
            current_A = coarse_A
            current_level += 1
        
        # æ·»åŠ æœ€ç²—å±‚
        if current_A.shape[0] > 0:
            level_data = {
                'matrix': current_A,
                'size': current_A.shape[0],
                'level': current_level
            }
            self.levels.append(level_data)
        
        self.is_setup = True
        self.performance_stats['setup_time'] = time.time() - start_time
        print(f"âœ… å¢å¼ºå‹AMGè®¾ç½®å®Œæˆï¼Œå…± {len(self.levels)} å±‚")
        print(f"   è®¾ç½®æ—¶é—´: {self.performance_stats['setup_time']:.4f}s")
    
    def _build_advanced_interpolation_operator(self, A: sp.spmatrix, 
                                             coarse_points: List[int], 
                                             fine_points: List[int]) -> sp.spmatrix:
        """æ„å»ºé«˜çº§æ’å€¼ç®—å­"""
        n = A.shape[0]
        n_coarse = len(coarse_points)
        
        # æ„å»ºæ’å€¼ç®—å­
        P_data = []
        P_rows = []
        P_cols = []
        
        # ç²—ç½‘æ ¼ç‚¹ï¼šå•ä½æ’å€¼
        for i, coarse_point in enumerate(coarse_points):
            P_data.append(1.0)
            P_rows.append(coarse_point)
            P_cols.append(i)
        
        # ç»†ç½‘æ ¼ç‚¹ï¼šåŸºäºå¼ºè¿æ¥çš„æ’å€¼
        for fine_point in fine_points:
            # æ‰¾åˆ°ä¸ç»†ç½‘æ ¼ç‚¹å¼ºè¿æ¥çš„ç²—ç½‘æ ¼ç‚¹
            strong_connections = self._find_strong_connections(A, fine_point, coarse_points)
            
            if strong_connections:
                # è®¡ç®—æ’å€¼æƒé‡
                weights = self._compute_advanced_interpolation_weights(A, fine_point, strong_connections)
                
                for coarse_idx, weight in zip(strong_connections, weights):
                    P_data.append(weight)
                    P_rows.append(fine_point)
                    P_cols.append(coarse_idx)
            else:
                # å¦‚æœæ²¡æœ‰å¼ºè¿æ¥ï¼Œä½¿ç”¨è·ç¦»æœ€è¿‘çš„ç²—ç½‘æ ¼ç‚¹
                distances = [abs(fine_point - cp) for cp in coarse_points]
                nearest_idx = np.argmin(distances)
                P_data.append(1.0)
                P_rows.append(fine_point)
                P_cols.append(nearest_idx)
        
        # æ„å»ºç¨€ç–çŸ©é˜µ
        P = sp.csr_matrix((P_data, (P_rows, P_cols)), shape=(n, n_coarse))
        
        return P
    
    def _find_strong_connections(self, A: sp.spmatrix, point: int, coarse_points: List[int]) -> List[int]:
        """æ‰¾åˆ°å¼ºè¿æ¥ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        row = A[point].toarray().flatten()
        diag = A[point, point]
        
        strong_connections = []
        for i, coarse_point in enumerate(coarse_points):
            if abs(row[coarse_point]) > self.config.strong_threshold * abs(diag):
                strong_connections.append(i)
        
        return strong_connections
    
    def _compute_advanced_interpolation_weights(self, A: sp.spmatrix, fine_point: int, 
                                             coarse_points: List[int]) -> List[float]:
        """è®¡ç®—é«˜çº§æ’å€¼æƒé‡"""
        # ä½¿ç”¨åŸºäºçŸ©é˜µå…ƒç´ çš„æƒé‡è®¡ç®—
        row = A[fine_point].toarray().flatten()
        diag = A[fine_point, fine_point]
        
        weights = []
        total_weight = 0.0
        
        for coarse_point in coarse_points:
            weight = abs(row[coarse_point]) / max(abs(diag), 1e-10)
            weights.append(weight)
            total_weight += weight
        
        # å½’ä¸€åŒ–æƒé‡
        if total_weight > 0:
            weights = [w / total_weight for w in weights]
        else:
            weights = [1.0 / len(coarse_points)] * len(coarse_points)
        
        return weights
    
    def solve(self, A: sp.spmatrix, b: np.ndarray, x0: np.ndarray = None) -> np.ndarray:
        """æ±‚è§£çº¿æ€§ç³»ç»Ÿï¼ˆå¢å¼ºç‰ˆï¼‰"""
        if not self.is_setup:
            self.setup(A, b)
        
        start_time = time.time()
        
        if x0 is None:
            x = np.zeros_like(b)
        else:
            x = x0.copy()
        
        # å¤šé‡ç½‘æ ¼è¿­ä»£
        for iteration in range(self.config.max_iterations):
            # æ ¹æ®é…ç½®é€‰æ‹©å¾ªç¯ç±»å‹
            if self.config.cycle_type == 'v':
                x = self.v_cycle(0, b, x)
            elif self.config.cycle_type == 'w':
                x = self.w_cycle(0, b, x)
            elif self.config.cycle_type == 'fmg':
                x = self.fmg_cycle(0, b, x)
            else:
                x = self.v_cycle(0, b, x)
            
            # æ£€æŸ¥æ”¶æ•›æ€§
            residual = b - A @ x
            residual_norm = np.linalg.norm(residual)
            
            if residual_norm < self.config.tolerance:
                print(f"âœ… å¢å¼ºå‹AMGæ”¶æ•›ï¼Œè¿­ä»£æ¬¡æ•°: {iteration + 1}")
                break
        
        self.performance_stats['solve_time'] = time.time() - start_time
        self.performance_stats['total_iterations'] = iteration + 1
        self.performance_stats['final_residual'] = residual_norm
        
        return x


class GeometricMultigridSolver(BaseMultigridSolver):
    """å¢å¼ºå‹å‡ ä½•å¤šé‡ç½‘æ ¼æ±‚è§£å™¨"""
    
    def __init__(self, config: MultigridConfig = None):
        super().__init__(config)
        self.meshes = []
        self.interpolation_operators = []
        self.restriction_operators = []
    
    def setup(self, A: sp.spmatrix, b: np.ndarray, mesh_data: Dict = None, **kwargs) -> None:
        """è®¾ç½®GMGå±‚æ¬¡ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        start_time = time.time()
        print("ğŸ”„ è®¾ç½®å¢å¼ºå‹å‡ ä½•å¤šé‡ç½‘æ ¼...")
        
        if mesh_data is None:
            raise ValueError("å‡ ä½•å¤šé‡ç½‘æ ¼éœ€è¦ç½‘æ ¼æ•°æ®")
        
        self.levels = []
        self.meshes = []
        self.interpolation_operators = []
        self.restriction_operators = []
        
        # æ„å»ºç½‘æ ¼å±‚æ¬¡
        current_mesh = mesh_data
        current_level = 0
        
        while current_level < self.config.max_levels:
            # å­˜å‚¨å½“å‰å±‚
            level_data = {
                'matrix': A,  # è¿™é‡Œåº”è¯¥æ ¹æ®ç½‘æ ¼é‡æ–°ç»„è£…çŸ©é˜µ
                'mesh': current_mesh,
                'size': len(current_mesh.get('nodes', [])),
                'level': current_level
            }
            self.levels.append(level_data)
            self.meshes.append(current_mesh)
            
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥ç»§ç»­ç²—åŒ–
            if len(current_mesh.get('nodes', [])) <= self.config.max_coarse_size:
                break
            
            # è‡ªé€‚åº”ç²—åŒ–ç½‘æ ¼
            if self.config.adaptive_coarsening:
                coarse_mesh = self.coarsening.geometric_coarsening(
                    current_mesh, self.config.max_coarse_size
                )
            else:
                coarse_mesh = self._simple_coarsen_mesh(current_mesh)
            
            # æ„å»ºæ’å€¼å’Œé™åˆ¶ç®—å­
            P, R = self._build_advanced_geometric_operators(current_mesh, coarse_mesh)
            
            self.interpolation_operators.append(P)
            self.restriction_operators.append(R)
            
            # æ›´æ–°åˆ°ä¸‹ä¸€å±‚
            current_mesh = coarse_mesh
            current_level += 1
        
        self.is_setup = True
        self.performance_stats['setup_time'] = time.time() - start_time
        print(f"âœ… å¢å¼ºå‹GMGè®¾ç½®å®Œæˆï¼Œå…± {len(self.levels)} å±‚")
        print(f"   è®¾ç½®æ—¶é—´: {self.performance_stats['setup_time']:.4f}s")
    
    def _simple_coarsen_mesh(self, mesh: Dict) -> Dict:
        """ç®€å•ç½‘æ ¼ç²—åŒ–ç­–ç•¥"""
        nodes = mesh.get('nodes', [])
        elements = mesh.get('elements', [])
        
        if len(nodes) <= 10:
            return mesh
        
        # é€‰æ‹©ç²—ç½‘æ ¼ç‚¹ï¼ˆæ¯éš”ä¸€ä¸ªç‚¹é€‰æ‹©ä¸€ä¸ªï¼‰
        coarse_nodes = nodes[::2]
        coarse_elements = []
        
        # é‡æ–°ç¼–å·å…ƒç´ 
        node_mapping = {i: j for j, i in enumerate(range(0, len(nodes), 2))}
        
        for element in elements:
            element_nodes = element.get('nodes', [])
            coarse_element_nodes = []
            
            for node in element_nodes:
                if node in node_mapping:
                    coarse_element_nodes.append(node_mapping[node])
            
            if len(coarse_element_nodes) >= 3:  # è‡³å°‘éœ€è¦3ä¸ªèŠ‚ç‚¹
                coarse_elements.append({'nodes': coarse_element_nodes})
        
        return {
            'nodes': coarse_nodes,
            'elements': coarse_elements
        }
    
    def _build_advanced_geometric_operators(self, fine_mesh: Dict, 
                                          coarse_mesh: Dict) -> Tuple[sp.spmatrix, sp.spmatrix]:
        """æ„å»ºé«˜çº§å‡ ä½•æ’å€¼å’Œé™åˆ¶ç®—å­"""
        fine_nodes = fine_mesh.get('nodes', [])
        coarse_nodes = coarse_mesh.get('nodes', [])
        
        n_fine = len(fine_nodes)
        n_coarse = len(coarse_nodes)
        
        # æ„å»ºæ’å€¼ç®—å­ï¼šä½¿ç”¨æ›´æ™ºèƒ½çš„æ’å€¼ç­–ç•¥
        P_data = []
        P_rows = []
        P_cols = []
        
        for i, fine_node in enumerate(fine_nodes):
            # æ‰¾åˆ°æœ€è¿‘çš„ç²—ç½‘æ ¼ç‚¹
            distances = [np.linalg.norm(np.array(fine_node) - np.array(coarse_node)) 
                        for coarse_node in coarse_nodes]
            nearest_coarse = np.argmin(distances)
            
            # è®¡ç®—æ’å€¼æƒé‡ï¼ˆåŸºäºè·ç¦»ï¼‰
            min_distance = distances[nearest_coarse]
            if min_distance > 0:
                weight = 1.0 / (1.0 + min_distance)
            else:
                weight = 1.0
            
            P_data.append(weight)
            P_rows.append(i)
            P_cols.append(nearest_coarse)
        
        P = sp.csr_matrix((P_data, (P_rows, P_cols)), shape=(n_fine, n_coarse))
        R = P.T  # é™åˆ¶ç®—å­ä¸ºæ’å€¼ç®—å­çš„è½¬ç½®
        
        return P, R
    
    def solve(self, A: sp.spmatrix, b: np.ndarray, x0: np.ndarray = None, 
              mesh_data: Dict = None) -> np.ndarray:
        """æ±‚è§£çº¿æ€§ç³»ç»Ÿï¼ˆå¢å¼ºç‰ˆï¼‰"""
        if not self.is_setup:
            self.setup(A, b, mesh_data)
        
        start_time = time.time()
        
        if x0 is None:
            x = np.zeros_like(b)
        else:
            x = x0.copy()
        
        # å¤šé‡ç½‘æ ¼è¿­ä»£
        for iteration in range(self.config.max_iterations):
            # æ ¹æ®é…ç½®é€‰æ‹©å¾ªç¯ç±»å‹
            if self.config.cycle_type == 'v':
                x = self.v_cycle(0, b, x)
            elif self.config.cycle_type == 'w':
                x = self.w_cycle(0, b, x)
            elif self.config.cycle_type == 'fmg':
                x = self.fmg_cycle(0, b, x)
            else:
                x = self.v_cycle(0, b, x)
            
            # æ£€æŸ¥æ”¶æ•›æ€§
            residual = b - A @ x
            residual_norm = np.linalg.norm(residual)
            
            if residual_norm < self.config.tolerance:
                print(f"âœ… å¢å¼ºå‹GMGæ”¶æ•›ï¼Œè¿­ä»£æ¬¡æ•°: {iteration + 1}")
                break
        
        self.performance_stats['solve_time'] = time.time() - start_time
        self.performance_stats['total_iterations'] = iteration + 1
        self.performance_stats['final_residual'] = residual_norm
        
        return x


# å·¥å‚å‡½æ•°
def create_multigrid_solver(solver_type: str = 'amg', config: MultigridConfig = None) -> BaseMultigridSolver:
    """åˆ›å»ºå¢å¼ºå‹å¤šé‡ç½‘æ ¼æ±‚è§£å™¨"""
    if solver_type == 'amg':
        return AlgebraicMultigridSolver(config)
    elif solver_type == 'gmg':
        return GeometricMultigridSolver(config)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å¤šé‡ç½‘æ ¼æ±‚è§£å™¨ç±»å‹: {solver_type}")


def create_multigrid_config(**kwargs) -> MultigridConfig:
    """åˆ›å»ºå¢å¼ºå‹å¤šé‡ç½‘æ ¼é…ç½®"""
    return MultigridConfig(**kwargs)


def benchmark_multigrid_solvers(A: sp.spmatrix, b: np.ndarray, 
                               configs: List[MultigridConfig] = None) -> Dict:
    """å¤šé‡ç½‘æ ¼æ±‚è§£å™¨æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    if configs is None:
        configs = [
            MultigridConfig(smoother='jacobi', cycle_type='v'),
            MultigridConfig(smoother='gauss_seidel', cycle_type='v'),
            MultigridConfig(smoother='chebyshev', cycle_type='v'),
            MultigridConfig(smoother='jacobi', cycle_type='w'),
            MultigridConfig(smoother='jacobi', cycle_type='fmg'),
        ]
    
    results = {}
    
    for i, config in enumerate(configs):
        print(f"\nğŸ§ª æµ‹è¯•é…ç½® {i+1}: {config.smoother} + {config.cycle_type}-cycle")
        
        # åˆ›å»ºæ±‚è§£å™¨
        solver = create_multigrid_solver('amg', config)
        
        # è®¾ç½®å’Œæ±‚è§£
        start_time = time.time()
        solver.setup(A, b)
        setup_time = time.time() - start_time
        
        start_time = time.time()
        x = solver.solve(A, b)
        solve_time = time.time() - start_time
        
        # è®¡ç®—æ®‹å·®
        residual = b - A @ x
        residual_norm = np.linalg.norm(residual)
        
        # å­˜å‚¨ç»“æœ
        config_name = f"{config.smoother}_{config.cycle_type}"
        results[config_name] = {
            'setup_time': setup_time,
            'solve_time': solve_time,
            'total_time': setup_time + solve_time,
            'iterations': solver.performance_stats['total_iterations'],
            'final_residual': residual_norm,
            'performance_stats': solver.performance_stats
        }
        
        print(f"   è®¾ç½®æ—¶é—´: {setup_time:.4f}s")
        print(f"   æ±‚è§£æ—¶é—´: {solve_time:.4f}s")
        print(f"   è¿­ä»£æ¬¡æ•°: {solver.performance_stats['total_iterations']}")
        print(f"   æœ€ç»ˆæ®‹å·®: {residual_norm:.2e}")
    
    return results
