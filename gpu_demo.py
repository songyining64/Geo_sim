"""
GPUåŠ é€Ÿæ¼”ç¤ºè„šæœ¬
"""

import numpy as np
import time

def demo_gpu_acceleration():
    """æ¼”ç¤ºGPUåŠ é€ŸåŠŸèƒ½"""
    print("ğŸš€ GPUåŠ é€Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # æµ‹è¯•çŸ©é˜µä¹˜æ³•
    print("ğŸ“Š æµ‹è¯•çŸ©é˜µä¹˜æ³•...")
    size = 1000
    A = np.random.rand(size, size).astype(np.float32)
    B = np.random.rand(size, size).astype(np.float32)
    
    # CPUè®¡ç®—
    start_time = time.time()
    C_cpu = np.dot(A, B)
    cpu_time = time.time() - start_time
    
    print(f"   CPUæ—¶é—´: {cpu_time:.4f} ç§’")
    print(f"   çŸ©é˜µå¤§å°: {size}x{size}")
    
    # å°è¯•GPUè®¡ç®—
    try:
        import cupy as cp
        print("   ğŸ¯ å°è¯•CuPy GPUåŠ é€Ÿ...")
        
        start_time = time.time()
        A_gpu = cp.asarray(A)
        B_gpu = cp.asarray(B)
        C_gpu = cp.dot(A_gpu, B_gpu)
        result = cp.asnumpy(C_gpu)
        gpu_time = time.time() - start_time
        
        error = np.linalg.norm(C_cpu - result) / np.linalg.norm(C_cpu)
        
        print(f"   GPUæ—¶é—´: {gpu_time:.4f} ç§’")
        print(f"   åŠ é€Ÿæ¯”: {cpu_time / gpu_time:.2f}x")
        print(f"   è¯¯å·®: {error:.2e}")
        
    except ImportError:
        print("   âŒ CuPyä¸å¯ç”¨ï¼Œè·³è¿‡GPUè®¡ç®—")
    
    # æµ‹è¯•çº¿æ€§ç³»ç»Ÿæ±‚è§£
    print("\nğŸ”§ æµ‹è¯•çº¿æ€§ç³»ç»Ÿæ±‚è§£...")
    A = np.random.rand(500, 500).astype(np.float32)
    A = A + A.T + 500 * np.eye(500)
    b = np.random.rand(500).astype(np.float32)
    
    start_time = time.time()
    x_cpu = np.linalg.solve(A, b)
    cpu_time = time.time() - start_time
    
    print(f"   CPUæ—¶é—´: {cpu_time:.4f} ç§’")
    
    try:
        import cupy as cp
        print("   ğŸ¯ å°è¯•CuPy GPUæ±‚è§£...")
        
        start_time = time.time()
        A_gpu = cp.asarray(A)
        b_gpu = cp.asarray(b)
        x_gpu = cp.linalg.solve(A_gpu, b_gpu)
        result = cp.asnumpy(x_gpu)
        gpu_time = time.time() - start_time
        
        error = np.linalg.norm(x_cpu - result) / np.linalg.norm(x_cpu)
        
        print(f"   GPUæ—¶é—´: {gpu_time:.4f} ç§’")
        print(f"   åŠ é€Ÿæ¯”: {cpu_time / gpu_time:.2f}x")
        print(f"   è¯¯å·®: {error:.2e}")
        
    except ImportError:
        print("   âŒ CuPyä¸å¯ç”¨ï¼Œè·³è¿‡GPUæ±‚è§£")
    
    print("\nâœ… GPUåŠ é€Ÿæ¼”ç¤ºå®Œæˆ!")


def demo_parallel_computing():
    """æ¼”ç¤ºå¹¶è¡Œè®¡ç®—åŠŸèƒ½"""
    print("\nğŸ”„ å¹¶è¡Œè®¡ç®—æ¼”ç¤º")
    print("=" * 50)
    
    try:
        from mpi4py import MPI
        
        comm = MPI.COMM_WORLD
        rank = comm.Get_rank()
        size = comm.Get_size()
        
        print(f"   MPIè¿›ç¨‹: {rank}/{size}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        n_points = 1000
        A = np.random.rand(n_points, n_points)
        A = A + A.T + n_points * np.eye(n_points)
        b = np.random.rand(n_points)
        
        # åŸŸåˆ†è§£
        points_per_process = n_points // size
        start_idx = rank * points_per_process
        end_idx = start_idx + points_per_process if rank < size - 1 else n_points
        
        local_b = b[start_idx:end_idx]
        local_A = A[start_idx:end_idx, :]
        
        # æœ¬åœ°æ±‚è§£
        from scipy.sparse.linalg import spsolve
        local_x = spsolve(local_A, local_b)
        
        # æ”¶é›†ç»“æœ
        all_x = comm.gather(local_x, root=0)
        
        if rank == 0:
            x_parallel = np.concatenate(all_x)
            
            # ä¸²è¡Œæ±‚è§£å¯¹æ¯”
            start_time = time.time()
            x_serial = np.linalg.solve(A, b)
            serial_time = time.time() - start_time
            
            error = np.linalg.norm(x_parallel - x_serial) / np.linalg.norm(x_serial)
            
            print(f"   ä¸²è¡Œæ—¶é—´: {serial_time:.4f} ç§’")
            print(f"   å¹¶è¡Œè¿›ç¨‹æ•°: {size}")
            print(f"   è¯¯å·®: {error:.2e}")
        
        print("   âœ… å¹¶è¡Œè®¡ç®—æ¼”ç¤ºå®Œæˆ!")
        
    except ImportError:
        print("   âŒ MPI4pyä¸å¯ç”¨ï¼Œè·³è¿‡å¹¶è¡Œè®¡ç®—")


def demo_ml_optimization():
    """æ¼”ç¤ºæœºå™¨å­¦ä¹ ä¼˜åŒ–åŠŸèƒ½"""
    print("\nğŸ¤– æœºå™¨å­¦ä¹ ä¼˜åŒ–æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    n_samples = 1000
    X = np.random.rand(n_samples, 2) * 10
    y = np.sin(X[:, 0]) * np.cos(X[:, 1]) + 0.1 * np.random.randn(n_samples)
    
    # æµ‹è¯•é«˜æ–¯è¿‡ç¨‹å›å½’
    try:
        from sklearn.gaussian_process import GaussianProcessRegressor
        from sklearn.gaussian_process.kernels import RBF, ConstantKernel
        
        print("   ğŸ“Š æµ‹è¯•é«˜æ–¯è¿‡ç¨‹å›å½’...")
        
        kernel = ConstantKernel(1.0) * RBF(length_scale=1.0)
        gp = GaussianProcessRegressor(kernel=kernel, random_state=42)
        
        start_time = time.time()
        gp.fit(X, y)
        training_time = time.time() - start_time
        
        X_test = np.random.rand(100, 2) * 10
        start_time = time.time()
        y_pred = gp.predict(X_test)
        prediction_time = time.time() - start_time
        
        print(f"   è®­ç»ƒæ—¶é—´: {training_time:.4f} ç§’")
        print(f"   é¢„æµ‹æ—¶é—´: {prediction_time:.4f} ç§’")
        print(f"   é¢„æµ‹æ ·æœ¬æ•°: {len(X_test)}")
        
    except ImportError:
        print("   âŒ scikit-learnä¸å¯ç”¨ï¼Œè·³è¿‡é«˜æ–¯è¿‡ç¨‹å›å½’")
    
    # æµ‹è¯•ç¥ç»ç½‘ç»œ
    try:
        import torch
        import torch.nn as nn
        import torch.optim as optim
        
        print("   ğŸ§  æµ‹è¯•ç¥ç»ç½‘ç»œ...")
        
        class SimpleNN(nn.Module):
            def __init__(self):
                super(SimpleNN, self).__init__()
                self.network = nn.Sequential(
                    nn.Linear(2, 64),
                    nn.ReLU(),
                    nn.Linear(64, 32),
                    nn.ReLU(),
                    nn.Linear(32, 1)
                )
            
            def forward(self, x):
                return self.network(x)
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = SimpleNN().to(device)
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.MSELoss()
        
        X_tensor = torch.FloatTensor(X).to(device)
        y_tensor = torch.FloatTensor(y).to(device)
        
        start_time = time.time()
        for epoch in range(50):
            optimizer.zero_grad()
            outputs = model(X_tensor)
            loss = criterion(outputs, y_tensor)
            loss.backward()
            optimizer.step()
        
        training_time = time.time() - start_time
        
        X_test_tensor = torch.FloatTensor(X_test).to(device)
        start_time = time.time()
        with torch.no_grad():
            y_pred_nn = model(X_test_tensor).cpu().numpy()
        prediction_time = time.time() - start_time
        
        print(f"   è®­ç»ƒæ—¶é—´: {training_time:.4f} ç§’")
        print(f"   é¢„æµ‹æ—¶é—´: {prediction_time:.4f} ç§’")
        print(f"   è®¾å¤‡: {device}")
        
    except ImportError:
        print("   âŒ PyTorchä¸å¯ç”¨ï¼Œè·³è¿‡ç¥ç»ç½‘ç»œ")
    
    print("   âœ… æœºå™¨å­¦ä¹ ä¼˜åŒ–æ¼”ç¤ºå®Œæˆ!")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ GPUåŠ é€Ÿç»¼åˆæ¼”ç¤º")
    print("=" * 80)
    
    demo_gpu_acceleration()
    demo_parallel_computing()
    demo_ml_optimization()
    
    print("\n" + "=" * 80)
    print("âœ… GPUåŠ é€Ÿç»¼åˆæ¼”ç¤ºå®Œæˆ!")
    print("=" * 80)
    print("ğŸ¯ å®ç°çš„åŠŸèƒ½:")
    print("   â€¢ CUDA GPUåŠ é€Ÿè®¡ç®—")
    print("   â€¢ MPIå¹¶è¡Œè®¡ç®—")
    print("   â€¢ æœºå™¨å­¦ä¹ ä¼˜åŒ–")
    print("   â€¢ è‡ªåŠ¨å›é€€æœºåˆ¶")


if __name__ == "__main__":
    main() 