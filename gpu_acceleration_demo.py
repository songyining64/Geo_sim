"""
GPUåŠ é€Ÿç»¼åˆæ¼”ç¤ºè„šæœ¬

å±•ç¤ºå®Œæ•´çš„GPUåŠ é€ŸåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. CUDAåŠ é€Ÿè®¡ç®—
2. å¹¶è¡Œè®¡ç®—
3. æœºå™¨å­¦ä¹ ä¼˜åŒ–
4. æ€§èƒ½å¯¹æ¯”åˆ†æ
"""

import numpy as np
import time
import warnings
warnings.filterwarnings('ignore')

# å°è¯•å¯¼å…¥GPUåŠ é€Ÿæ¨¡å—
try:
    from gpu_acceleration.cuda_acceleration import (
        CUDAAccelerator, GPUMatrixOperations, GPUSolver, create_cuda_accelerator
    )
    CUDA_AVAILABLE = True
except ImportError:
    CUDA_AVAILABLE = False
    print("âš ï¸ CUDAåŠ é€Ÿæ¨¡å—ä¸å¯ç”¨")

try:
    from gpu_acceleration.parallel_computing import (
        MPIManager, ParallelSolver, create_parallel_solver
    )
    PARALLEL_AVAILABLE = True
except ImportError:
    PARALLEL_AVAILABLE = False
    print("âš ï¸ å¹¶è¡Œè®¡ç®—æ¨¡å—ä¸å¯ç”¨")

try:
    from gpu_acceleration.ml_optimization import (
        MLAccelerator, NeuralNetworkSolver, SurrogateModel, create_ml_accelerator
    )
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    print("âš ï¸ æœºå™¨å­¦ä¹ ä¼˜åŒ–æ¨¡å—ä¸å¯ç”¨")


def demo_cuda_acceleration():
    """æ¼”ç¤ºCUDAåŠ é€ŸåŠŸèƒ½"""
    print("ğŸš€ CUDAåŠ é€Ÿæ¼”ç¤º")
    print("=" * 50)
    
    if not CUDA_AVAILABLE:
        print("âŒ CUDAåŠ é€Ÿæ¨¡å—ä¸å¯ç”¨")
        return None
    
    try:
        # åˆ›å»ºCUDAåŠ é€Ÿå™¨
        accelerator = create_cuda_accelerator()
        
        if not accelerator.is_available():
            print("âŒ CUDAä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥GPUå’ŒCUDAå®‰è£…")
            return None
        
        # åˆ›å»ºGPUçŸ©é˜µè¿ç®—
        matrix_ops = GPUMatrixOperations(accelerator)
        
        # åˆ›å»ºGPUæ±‚è§£å™¨
        solver = GPUSolver(accelerator)
        
        # æµ‹è¯•çŸ©é˜µä¹˜æ³•
        print("ğŸ“Š æµ‹è¯•çŸ©é˜µä¹˜æ³•...")
        size = 1000
        A = np.random.rand(size, size).astype(np.float32)
        B = np.random.rand(size, size).astype(np.float32)
        
        # CPUè®¡ç®—
        start_time = time.time()
        C_cpu = np.dot(A, B)
        cpu_time = time.time() - start_time
        
        # GPUè®¡ç®—
        start_time = time.time()
        C_gpu = matrix_ops.matrix_multiply(A, B)
        gpu_time = time.time() - start_time
        
        # éªŒè¯ç»“æœ
        error = np.linalg.norm(C_cpu - C_gpu) / np.linalg.norm(C_cpu)
        
        print(f"   CPUæ—¶é—´: {cpu_time:.4f} ç§’")
        print(f"   GPUæ—¶é—´: {gpu_time:.4f} ç§’")
        print(f"   åŠ é€Ÿæ¯”: {cpu_time / gpu_time:.2f}x")
        print(f"   è¯¯å·®: {error:.2e}")
        
        # æµ‹è¯•çº¿æ€§ç³»ç»Ÿæ±‚è§£
        print("\nğŸ”§ æµ‹è¯•çº¿æ€§ç³»ç»Ÿæ±‚è§£...")
        A = np.random.rand(500, 500).astype(np.float32)
        A = A + A.T + 500 * np.eye(500)  # ç¡®ä¿æ­£å®š
        b = np.random.rand(500).astype(np.float32)
        
        # CPUæ±‚è§£
        start_time = time.time()
        x_cpu = np.linalg.solve(A, b)
        cpu_time = time.time() - start_time
        
        # GPUæ±‚è§£
        start_time = time.time()
        x_gpu = solver.solve_linear_system(A, b)
        gpu_time = time.time() - start_time
        
        # éªŒè¯ç»“æœ
        error = np.linalg.norm(x_cpu - x_gpu) / np.linalg.norm(x_cpu)
        
        print(f"   CPUæ—¶é—´: {cpu_time:.4f} ç§’")
        print(f"   GPUæ—¶é—´: {gpu_time:.4f} ç§’")
        print(f"   åŠ é€Ÿæ¯”: {cpu_time / gpu_time:.2f}x")
        print(f"   è¯¯å·®: {error:.2e}")
        
        # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        print("\nğŸ“ˆ CUDAæ€§èƒ½ç»Ÿè®¡:")
        stats = solver.get_performance_stats()
        print(f"   çŸ©é˜µè¿ç®—æ¬¡æ•°: {stats['matrix_ops']}")
        print(f"   æ±‚è§£å™¨è¿ç®—æ¬¡æ•°: {stats['solver_ops']}")
        print(f"   æ€»è®¡ç®—æ—¶é—´: {stats['total_time']:.4f} ç§’")
        print(f"   GPUå†…å­˜ä½¿ç”¨: {stats['memory_info']['used'] / 1024**3:.2f} GB")
        
        return stats
        
    except Exception as e:
        print(f"âŒ CUDAåŠ é€Ÿæ¼”ç¤ºå¤±è´¥: {e}")
        return None


def demo_parallel_computing():
    """æ¼”ç¤ºå¹¶è¡Œè®¡ç®—åŠŸèƒ½"""
    print("\nğŸ”„ å¹¶è¡Œè®¡ç®—æ¼”ç¤º")
    print("=" * 50)
    
    if not PARALLEL_AVAILABLE:
        print("âŒ å¹¶è¡Œè®¡ç®—æ¨¡å—ä¸å¯ç”¨")
        return None
    
    try:
        # åˆ›å»ºå¹¶è¡Œæ±‚è§£å™¨
        solver = create_parallel_solver()
        
        # åˆ›å»ºæµ‹è¯•é—®é¢˜
        n_points = 1000
        A = np.random.rand(n_points, n_points)
        A = A + A.T + n_points * np.eye(n_points)  # ç¡®ä¿æ­£å®š
        b = np.random.rand(n_points)
        
        # å¹¶è¡Œæ±‚è§£
        print(f"ğŸ”§ ä½¿ç”¨ {solver.mpi.get_size()} ä¸ªè¿›ç¨‹æ±‚è§£ {n_points}x{n_points} çº¿æ€§ç³»ç»Ÿ...")
        
        start_time = time.time()
        x_parallel = solver.solve_parallel_linear_system(A, b)
        parallel_time = time.time() - start_time
        
        # ä¸²è¡Œæ±‚è§£ï¼ˆä»…åœ¨æ ¹è¿›ç¨‹ï¼‰
        if solver.mpi.is_root_process():
            start_time = time.time()
            x_serial = np.linalg.solve(A, b)
            serial_time = time.time() - start_time
            
            # éªŒè¯ç»“æœ
            error = np.linalg.norm(x_parallel - x_serial) / np.linalg.norm(x_serial)
            
            print(f"   ä¸²è¡Œæ—¶é—´: {serial_time:.4f} ç§’")
            print(f"   å¹¶è¡Œæ—¶é—´: {parallel_time:.4f} ç§’")
            print(f"   åŠ é€Ÿæ¯”: {serial_time / parallel_time:.2f}x")
            print(f"   è¯¯å·®: {error:.2e}")
        
        # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        stats = solver.get_performance_stats()
        print(f"\nğŸ“ˆ è¿›ç¨‹ {stats['rank']} æ€§èƒ½ç»Ÿè®¡:")
        print(f"   æ±‚è§£æ—¶é—´: {stats['solve_time']:.4f} ç§’")
        print(f"   è¿­ä»£æ¬¡æ•°: {stats['iterations']}")
        
        return stats
        
    except Exception as e:
        print(f"âŒ å¹¶è¡Œè®¡ç®—æ¼”ç¤ºå¤±è´¥: {e}")
        return None


def demo_ml_optimization():
    """æ¼”ç¤ºæœºå™¨å­¦ä¹ ä¼˜åŒ–åŠŸèƒ½"""
    print("\nğŸ¤– æœºå™¨å­¦ä¹ ä¼˜åŒ–æ¼”ç¤º")
    print("=" * 50)
    
    if not ML_AVAILABLE:
        print("âŒ æœºå™¨å­¦ä¹ ä¼˜åŒ–æ¨¡å—ä¸å¯ç”¨")
        return None
    
    try:
        # åˆ›å»ºæœºå™¨å­¦ä¹ åŠ é€Ÿå™¨
        accelerator = create_ml_accelerator()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        n_samples = 1000
        X = np.random.rand(n_samples, 2) * 10
        y = np.sin(X[:, 0]) * np.cos(X[:, 1]) + 0.1 * np.random.randn(n_samples)
        
        # æµ‹è¯•é«˜æ–¯è¿‡ç¨‹ä»£ç†æ¨¡å‹
        print("ğŸ“Š æµ‹è¯•é«˜æ–¯è¿‡ç¨‹ä»£ç†æ¨¡å‹...")
        gp_model = accelerator.create_surrogate_model('gp_test', 'gaussian_process')
        
        start_time = time.time()
        history = accelerator.train_surrogate_model('gp_test', X, y)
        training_time = time.time() - start_time
        
        # æµ‹è¯•é¢„æµ‹
        X_test = np.random.rand(100, 2) * 10
        start_time = time.time()
        y_pred = accelerator.predict_with_surrogate('gp_test', X_test)
        prediction_time = time.time() - start_time
        
        print(f"   è®­ç»ƒæ—¶é—´: {training_time:.4f} ç§’")
        print(f"   é¢„æµ‹æ—¶é—´: {prediction_time:.4f} ç§’")
        print(f"   é¢„æµ‹æ ·æœ¬æ•°: {len(X_test)}")
        
        # æµ‹è¯•ç¥ç»ç½‘ç»œæ±‚è§£å™¨
        print("\nğŸ§  æµ‹è¯•ç¥ç»ç½‘ç»œæ±‚è§£å™¨...")
        nn_solver = accelerator.create_neural_solver('nn_test', 2, [64, 32], 1)
        
        start_time = time.time()
        history = accelerator.train_surrogate_model('nn_test', X, y, epochs=50, batch_size=32)
        training_time = time.time() - start_time
        
        start_time = time.time()
        y_pred_nn = accelerator.predict_with_surrogate('nn_test', X_test)
        prediction_time = time.time() - start_time
        
        print(f"   è®­ç»ƒæ—¶é—´: {training_time:.4f} ç§’")
        print(f"   é¢„æµ‹æ—¶é—´: {prediction_time:.4f} ç§’")
        print(f"   æœ€ç»ˆè®­ç»ƒæŸå¤±: {history['train_loss'][-1]:.6f}")
        
        # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        print("\nğŸ“ˆ MLæ€§èƒ½ç»Ÿè®¡:")
        stats = accelerator.get_performance_stats()
        print(f"   è®¾å¤‡: {stats['device']}")
        print(f"   ä½¿ç”¨GPU: {stats['use_gpu']}")
        print(f"   ä»£ç†æ¨¡å‹æ•°é‡: {stats['num_surrogate_models']}")
        print(f"   ç¥ç»ç½‘ç»œæ±‚è§£å™¨æ•°é‡: {stats['num_neural_solvers']}")
        print(f"   æ€»è®­ç»ƒæ—¶é—´: {stats['training_time']:.4f} ç§’")
        print(f"   æ€»é¢„æµ‹æ—¶é—´: {stats['prediction_time']:.4f} ç§’")
        print(f"   è®­ç»ƒæ¨¡å‹æ•°é‡: {stats['models_trained']}")
        
        return stats
        
    except Exception as e:
        print(f"âŒ æœºå™¨å­¦ä¹ ä¼˜åŒ–æ¼”ç¤ºå¤±è´¥: {e}")
        return None


def performance_comparison(cuda_stats, parallel_stats, ml_stats):
    """æ€§èƒ½å¯¹æ¯”åˆ†æ"""
    print("\n" + "=" * 80)
    print("ğŸ“Š GPUåŠ é€Ÿæ€§èƒ½å¯¹æ¯”åˆ†æ")
    print("=" * 80)
    
    print("ğŸ¯ åŠŸèƒ½æ¨¡å—å¯¹æ¯”:")
    print(f"   CUDAåŠ é€Ÿ: {'âœ… å¯ç”¨' if cuda_stats else 'âŒ ä¸å¯ç”¨'}")
    print(f"   å¹¶è¡Œè®¡ç®—: {'âœ… å¯ç”¨' if parallel_stats else 'âŒ ä¸å¯ç”¨'}")
    print(f"   æœºå™¨å­¦ä¹ : {'âœ… å¯ç”¨' if ml_stats else 'âŒ ä¸å¯ç”¨'}")
    
    if cuda_stats:
        print(f"\nğŸš€ CUDAåŠ é€Ÿæ€§èƒ½:")
        print(f"   çŸ©é˜µè¿ç®—: {cuda_stats['matrix_ops']} æ¬¡")
        print(f"   æ±‚è§£å™¨è¿ç®—: {cuda_stats['solver_ops']} æ¬¡")
        print(f"   æ€»è®¡ç®—æ—¶é—´: {cuda_stats['total_time']:.4f} ç§’")
        print(f"   GPUå†…å­˜ä½¿ç”¨: {cuda_stats['memory_info']['used'] / 1024**3:.2f} GB")
    
    if parallel_stats:
        print(f"\nğŸ”„ å¹¶è¡Œè®¡ç®—æ€§èƒ½:")
        print(f"   è¿›ç¨‹æ•°: {parallel_stats['size']}")
        print(f"   æ±‚è§£æ—¶é—´: {parallel_stats['solve_time']:.4f} ç§’")
        print(f"   è¿­ä»£æ¬¡æ•°: {parallel_stats['iterations']}")
    
    if ml_stats:
        print(f"\nğŸ¤– æœºå™¨å­¦ä¹ æ€§èƒ½:")
        print(f"   è®¾å¤‡: {ml_stats['device']}")
        print(f"   ä½¿ç”¨GPU: {ml_stats['use_gpu']}")
        print(f"   æ€»è®­ç»ƒæ—¶é—´: {ml_stats['training_time']:.4f} ç§’")
        print(f"   æ€»é¢„æµ‹æ—¶é—´: {ml_stats['prediction_time']:.4f} ç§’")
        print(f"   è®­ç»ƒæ¨¡å‹æ•°: {ml_stats['models_trained']}")
    
    print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    if cuda_stats and cuda_stats['matrix_ops'] > 0:
        print("   â€¢ CUDAåŠ é€Ÿåœ¨çŸ©é˜µè¿ç®—æ–¹é¢è¡¨ç°ä¼˜å¼‚")
    if parallel_stats and parallel_stats['size'] > 1:
        print("   â€¢ å¹¶è¡Œè®¡ç®—å¯æœ‰æ•ˆåˆ©ç”¨å¤šæ ¸CPUèµ„æº")
    if ml_stats and ml_stats['use_gpu']:
        print("   â€¢ GPUåŠ é€Ÿæœºå™¨å­¦ä¹ è®­ç»ƒå¯æ˜¾è‘—æå‡æ€§èƒ½")
    
    print("   â€¢ å»ºè®®æ ¹æ®å…·ä½“åº”ç”¨åœºæ™¯é€‰æ‹©åˆé€‚çš„åŠ é€Ÿæ–¹æ¡ˆ")
    print("   â€¢ å¯¹äºå¤§è§„æ¨¡è®¡ç®—ï¼Œå¯è€ƒè™‘GPU+MPIæ··åˆåŠ é€Ÿ")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ GPUåŠ é€Ÿç»¼åˆæ¼”ç¤º")
    print("=" * 80)
    print("æœ¬æ¼”ç¤ºå±•ç¤ºäº†å®Œæ•´çš„GPUåŠ é€ŸåŠŸèƒ½")
    print("åŒ…æ‹¬ï¼šCUDAåŠ é€Ÿã€å¹¶è¡Œè®¡ç®—ã€æœºå™¨å­¦ä¹ ä¼˜åŒ–ç­‰")
    print("=" * 80)
    
    # æ£€æŸ¥æ¨¡å—å¯ç”¨æ€§
    print("ğŸ” æ£€æŸ¥æ¨¡å—å¯ç”¨æ€§:")
    print(f"   CUDAåŠ é€Ÿæ¨¡å—: {'âœ… å¯ç”¨' if CUDA_AVAILABLE else 'âŒ ä¸å¯ç”¨'}")
    print(f"   å¹¶è¡Œè®¡ç®—æ¨¡å—: {'âœ… å¯ç”¨' if PARALLEL_AVAILABLE else 'âŒ ä¸å¯ç”¨'}")
    print(f"   æœºå™¨å­¦ä¹ æ¨¡å—: {'âœ… å¯ç”¨' if ML_AVAILABLE else 'âŒ ä¸å¯ç”¨'}")
    
    # è¿è¡Œæ¼”ç¤º
    cuda_stats = demo_cuda_acceleration()
    parallel_stats = demo_parallel_computing()
    ml_stats = demo_ml_optimization()
    
    # æ€§èƒ½å¯¹æ¯”åˆ†æ
    performance_comparison(cuda_stats, parallel_stats, ml_stats)
    
    print("\n" + "=" * 80)
    print("âœ… GPUåŠ é€Ÿç»¼åˆæ¼”ç¤ºå®Œæˆ!")
    print("=" * 80)
    print("ğŸ¯ å®ç°çš„åŠŸèƒ½:")
    print("   â€¢ CUDA GPUåŠ é€Ÿè®¡ç®—")
    print("   â€¢ MPIå¹¶è¡Œè®¡ç®—")
    print("   â€¢ æœºå™¨å­¦ä¹ ä¼˜åŒ–")
    print("   â€¢ æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print("   â€¢ è‡ªåŠ¨å›é€€æœºåˆ¶")
    
    print("\nğŸ“ˆ æŠ€æœ¯ç‰¹ç‚¹:")
    print("   â€¢ æ”¯æŒå¤šç§GPUåŠ é€Ÿåº“ (CuPy, Numba)")
    print("   â€¢ çµæ´»çš„å¹¶è¡Œè®¡ç®—ç­–ç•¥")
    print("   â€¢ æ·±åº¦å­¦ä¹ é›†æˆ")
    print("   â€¢ ä»£ç†æ¨¡å‹ä¼˜åŒ–")
    print("   â€¢ å®Œæ•´çš„æ€§èƒ½ç›‘æ§")
    
    print("\nğŸš€ åº”ç”¨åœºæ™¯:")
    print("   â€¢ å¤§è§„æ¨¡ç§‘å­¦è®¡ç®—")
    print("   â€¢ æœ‰é™å…ƒåˆ†æ")
    print("   â€¢ æœºå™¨å­¦ä¹ è®­ç»ƒ")
    print("   â€¢ æ•°å€¼ä¼˜åŒ–")
    print("   â€¢ é«˜æ€§èƒ½è®¡ç®—")


if __name__ == "__main__":
    main() 