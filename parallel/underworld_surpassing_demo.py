"""
è¶…è¶ŠUnderworldçš„å¹¶è¡Œæ±‚è§£å™¨æ¼”ç¤ºè„šæœ¬

å±•ç¤ºæ ¸å¿ƒçªç ´åŠŸèƒ½ï¼š
1. é€šä¿¡ä¼˜åŒ–
2. æ™ºèƒ½è´Ÿè½½å‡è¡¡
3. å¼‚æ„è®¡ç®—
4. è‡ªé€‚åº”ç®—æ³•é€‰æ‹©
5. æ€§èƒ½åŸºå‡†æµ‹è¯•
"""

import numpy as np
import scipy.sparse as sp
import time
import json
from pathlib import Path

# å¯¼å…¥æˆ‘ä»¬çš„é«˜çº§å¹¶è¡Œæ±‚è§£å™¨
from underworld_surpassing_solver import (
    AdvancedParallelConfig, 
    UnderworldSurpassingSolver,
    AdaptiveCommunicator,
    MLBasedLoadBalancer,
    HeterogeneousComputingManager,
    AdaptiveSolverSelector
)


def create_test_problems():
    """åˆ›å»ºä¸åŒç‰¹å¾çš„æµ‹è¯•é—®é¢˜"""
    print("ğŸ”§ åˆ›å»ºæµ‹è¯•é—®é¢˜...")
    
    test_problems = {}
    
    # 1. å¤§è§„æ¨¡ç¨€ç–é—®é¢˜ï¼ˆé€‚åˆGPUï¼‰
    print("   åˆ›å»ºå¤§è§„æ¨¡ç¨€ç–é—®é¢˜...")
    size = 50000
    A_sparse = sp.random(size, size, density=0.005, format='csr')
    A_sparse = A_sparse + A_sparse.T + sp.eye(size) * 2  # ç¡®ä¿æ­£å®šæ€§
    b_sparse = np.random.randn(size)
    test_problems['large_sparse'] = (A_sparse, b_sparse, 'é€‚åˆGPUåŠ é€Ÿçš„å¤§è§„æ¨¡ç¨€ç–é—®é¢˜')
    
    # 2. ä¸­ç­‰è§„æ¨¡é—®é¢˜ï¼ˆé€‚åˆOpenMPï¼‰
    print("   åˆ›å»ºä¸­ç­‰è§„æ¨¡é—®é¢˜...")
    size = 10000
    A_medium = sp.random(size, size, density=0.02, format='csr')
    A_medium = A_medium + A_medium.T + sp.eye(size) * 1.5
    b_medium = np.random.randn(size)
    test_problems['medium'] = (A_medium, b_medium, 'é€‚åˆOpenMPå¹¶è¡Œçš„ä¸­ç­‰è§„æ¨¡é—®é¢˜')
    
    # 3. å°è§„æ¨¡å¯†é›†é—®é¢˜ï¼ˆé€‚åˆCPUï¼‰
    print("   åˆ›å»ºå°è§„æ¨¡é—®é¢˜...")
    size = 2000
    A_small = sp.random(size, size, density=0.1, format='csr')
    A_small = A_small + A_small.T + sp.eye(size)
    b_small = np.random.randn(size)
    test_problems['small'] = (A_small, b_small, 'é€‚åˆCPUç›´æ¥æ±‚è§£çš„å°è§„æ¨¡é—®é¢˜')
    
    # 4. ç—…æ€æ¡ä»¶é—®é¢˜
    print("   åˆ›å»ºç—…æ€æ¡ä»¶é—®é¢˜...")
    size = 5000
    A_ill = sp.random(size, size, density=0.01, format='csr')
    A_ill = A_ill + A_ill.T + sp.eye(size) * 0.1  # æ¥è¿‘å¥‡å¼‚çš„çŸ©é˜µ
    b_ill = np.random.randn(size)
    test_problems['ill_conditioned'] = (A_ill, b_ill, 'ç—…æ€æ¡ä»¶é—®é¢˜ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†')
    
    # 5. å—å¯¹è§’ç»“æ„é—®é¢˜
    print("   åˆ›å»ºå—å¯¹è§’ç»“æ„é—®é¢˜...")
    size = 8000
    block_size = 1000
    A_block = sp.lil_matrix((size, size))
    
    for i in range(0, size, block_size):
        end_i = min(i + block_size, size)
        A_block[i:end_i, i:end_i] = sp.random(end_i - i, end_i - i, density=0.05) + sp.eye(end_i - i)
    
    A_block = A_block.tocsr()
    b_block = np.random.randn(size)
    test_problems['block_structured'] = (A_block, b_block, 'å—å¯¹è§’ç»“æ„é—®é¢˜ï¼Œé€‚åˆç‰¹æ®Šä¼˜åŒ–')
    
    print(f"âœ… æˆåŠŸåˆ›å»º {len(test_problems)} ä¸ªæµ‹è¯•é—®é¢˜")
    return test_problems


def demonstrate_communication_optimization():
    """æ¼”ç¤ºé€šä¿¡ä¼˜åŒ–åŠŸèƒ½"""
    print("\nğŸš€ æ¼”ç¤ºé€šä¿¡ä¼˜åŒ–åŠŸèƒ½")
    print("=" * 50)
    
    # åˆ›å»ºé€šä¿¡ä¼˜åŒ–å™¨
    communicator = AdaptiveCommunicator()
    
    # æ¨¡æ‹Ÿåˆ†åŒºä¿¡æ¯
    partition_info = {
        'method': 'metis',
        'num_partitions': 4,
        'boundary_elements': [100, 150, 200, 120]
    }
    
    # æ¨¡æ‹Ÿæ•°æ®å¯†åº¦
    data_density = np.array([0.8, 0.3, 0.9, 0.2])
    
    print("ğŸ“Š åˆ†æé€šä¿¡æ¨¡å¼...")
    schedule = communicator.optimize_communication_pattern(partition_info, data_density)
    
    print(f"   é€šä¿¡è°ƒåº¦ç±»å‹: {schedule['type']}")
    if schedule['type'] == 'point_to_point':
        print(f"   é‚»å±…è¿›ç¨‹æ•°: {len(schedule['neighbors'])}")
        print(f"   é€šä¿¡é¡ºåº: {schedule['communication_order']}")
    elif schedule['type'] == 'collective':
        print(f"   é›†ä½“é€šä¿¡æ“ä½œ: {schedule['operation']}")
        print(f"   ä¼˜åŒ–ç­–ç•¥: {schedule['optimization']}")
    elif schedule['type'] == 'hybrid':
        print(f"   æ··åˆç­–ç•¥: ç‚¹å¯¹ç‚¹ + é›†ä½“é€šä¿¡")
    
    return schedule


def demonstrate_load_balancing():
    """æ¼”ç¤ºæ™ºèƒ½è´Ÿè½½å‡è¡¡åŠŸèƒ½"""
    print("\nâš–ï¸ æ¼”ç¤ºæ™ºèƒ½è´Ÿè½½å‡è¡¡åŠŸèƒ½")
    print("=" * 50)
    
    # åˆ›å»ºè´Ÿè½½å‡è¡¡å™¨
    load_balancer = MLBasedLoadBalancer()
    
    # æ¨¡æ‹Ÿå½“å‰è´Ÿè½½åˆ†å¸ƒ
    current_loads = np.array([1200, 800, 1500, 900])
    print(f"ğŸ“Š å½“å‰è´Ÿè½½åˆ†å¸ƒ: {current_loads}")
    
    # è®¡ç®—è´Ÿè½½ä¸å¹³è¡¡åº¦
    imbalance = load_balancer._compute_load_imbalance(current_loads)
    print(f"   è´Ÿè½½ä¸å¹³è¡¡åº¦: {imbalance:.4f}")
    
    # æ¨¡æ‹Ÿç½‘æ ¼ç‰¹å¾
    mesh_features = {
        'element_complexity': [1.2, 0.8, 1.5, 1.0],
        'elements': [1200, 800, 1500, 900]
    }
    
    # é¢„æµ‹è´Ÿè½½åˆ†å¸ƒ
    predicted_loads = load_balancer.predict_load_distribution(mesh_features, {})
    print(f"ğŸ”® é¢„æµ‹è´Ÿè½½åˆ†å¸ƒ: {predicted_loads}")
    
    # åŠ¨æ€è´Ÿè½½å‡è¡¡
    partition_info = {'method': 'metis', 'partitions': [0, 1, 2, 3]}
    balanced_partition = load_balancer.balance_load_dynamically(
        current_loads, mesh_features, partition_info
    )
    
    print(f"âœ… è´Ÿè½½å‡è¡¡å®Œæˆ")
    return balanced_partition


def demonstrate_heterogeneous_computing():
    """æ¼”ç¤ºå¼‚æ„è®¡ç®—åŠŸèƒ½"""
    print("\nğŸ–¥ï¸ æ¼”ç¤ºå¼‚æ„è®¡ç®—åŠŸèƒ½")
    print("=" * 50)
    
    # åˆ›å»ºå¼‚æ„è®¡ç®—ç®¡ç†å™¨
    config = AdvancedParallelConfig(
        use_gpu=True,
        use_openmp=True,
        cpu_threads=4
    )
    
    manager = HeterogeneousComputingManager(config)
    
    print(f"   ç¡¬ä»¶æ”¯æŒçŠ¶æ€:")
    print(f"     GPU: {'âœ… å¯ç”¨' if manager.gpu_available else 'âŒ ä¸å¯ç”¨'}")
    print(f"   OpenMP: {'âœ… å¯ç”¨' if manager.openmp_available else 'âŒ ä¸å¯ç”¨'}")
    
    # åˆ›å»ºæµ‹è¯•é—®é¢˜
    size = 3000
    A = sp.random(size, size, density=0.02, format='csr')
    A = A + A.T + sp.eye(size)
    b = np.random.randn(size)
    
    print(f"\nğŸ” æµ‹è¯•é—®é¢˜è§„æ¨¡: {size}")
    
    # æµ‹è¯•ä¸åŒæ±‚è§£å™¨
    solvers = ['auto', 'gpu_cg', 'openmp_cg', 'cpu_cg']
    
    for solver in solvers:
        print(f"\n   æµ‹è¯•æ±‚è§£å™¨: {solver}")
        start_time = time.time()
        
        try:
            solution = manager.solve_with_heterogeneous_computing(A, b, solver)
            solve_time = time.time() - start_time
            
            # éªŒè¯è§£çš„æ­£ç¡®æ€§
            residual = np.linalg.norm(b - A.dot(solution))
            print(f"     æ±‚è§£æ—¶é—´: {solve_time:.4f}s")
            print(f"     æ®‹å·®èŒƒæ•°: {residual:.2e}")
            
        except Exception as e:
            print(f"     âŒ æ±‚è§£å¤±è´¥: {e}")
    
    return manager


def demonstrate_adaptive_solver_selection():
    """æ¼”ç¤ºè‡ªé€‚åº”æ±‚è§£å™¨é€‰æ‹©åŠŸèƒ½"""
    print("\nğŸ§  æ¼”ç¤ºè‡ªé€‚åº”æ±‚è§£å™¨é€‰æ‹©åŠŸèƒ½")
    print("=" * 50)
    
    # åˆ›å»ºæ±‚è§£å™¨é€‰æ‹©å™¨
    config = AdvancedParallelConfig()
    selector = AdaptiveSolverSelector(config)
    
    # åˆ›å»ºä¸åŒç‰¹å¾çš„é—®é¢˜
    problems = {
        'large_sparse': (sp.random(15000, 15000, density=0.005, format='csr'), np.random.randn(15000)),
        'ill_conditioned': (sp.random(5000, 5000, density=0.01, format='csr') + sp.eye(5000) * 0.01, np.random.randn(5000)),
        'block_structured': (sp.block_diag([sp.random(1000, 1000, density=0.05) + sp.eye(1000) for _ in range(5)]), np.random.randn(5000))
    }
    
    available_solvers = ['gpu_cg', 'openmp_cg', 'cpu_cg', 'amg']
    
    for problem_name, (A, b) in problems.items():
        print(f"\nğŸ” åˆ†æé—®é¢˜: {problem_name}")
        print(f"   é—®é¢˜è§„æ¨¡: {A.shape[0]}")
        
        # é—®é¢˜åˆ†ç±»
        problem_type = selector.problem_classifier.classify_problem(A, b)
        print(f"   é—®é¢˜ç±»å‹: {problem_type}")
        
        # é€‰æ‹©æœ€ä¼˜æ±‚è§£å™¨
        optimal_solver = selector.select_optimal_solver(A, b, available_solvers)
        print(f"   æ¨èæ±‚è§£å™¨: {optimal_solver}")
        
        # æå–é—®é¢˜ç‰¹å¾
        features = selector.problem_classifier._extract_features(A, b)
        print(f"   é—®é¢˜ç‰¹å¾:")
        print(f"     è§„æ¨¡: {features['size']}")
        print(f"     ç¨€ç–æ€§: {features['sparsity']:.3f}")
        print(f"     æ¡ä»¶æ•°: {features['condition_number']:.2e}")
        print(f"     ç»“æ„: {features['structure']}")
    
    return selector


def run_comprehensive_benchmark():
    """è¿è¡Œå…¨é¢çš„æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("\nğŸ† è¿è¡Œå…¨é¢æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 50)
    
    # é…ç½®
    config = AdvancedParallelConfig(
        solver_type='adaptive',
        use_gpu=True,
        use_openmp=True,
        ml_based_balancing=True,
        adaptive_communication=True,
        max_iterations=1000,
        tolerance=1e-8
    )
    
    # åˆ›å»ºæ±‚è§£å™¨
    solver = UnderworldSurpassingSolver(config)
    
    # è·å–æµ‹è¯•é—®é¢˜
    test_problems = create_test_problems()
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    benchmark_results = {}
    
    for problem_name, (A, b, description) in test_problems.items():
        print(f"\nğŸ” åŸºå‡†æµ‹è¯•: {problem_name}")
        print(f"   æè¿°: {description}")
        print(f"   è§„æ¨¡: {A.shape[0]} x {A.shape[1]}")
        
        # ä½ çš„æ±‚è§£å™¨
        start_time = time.time()
        your_solution = solver.solve(A, b)
        your_time = time.time() - start_time
        
        # éªŒè¯è§£çš„æ­£ç¡®æ€§
        residual = np.linalg.norm(b - A.dot(your_solution))
        
        # Underworldä¼°è®¡æ—¶é—´
        uw_time = solver._estimate_underworld_time(A, b)
        
        # è®¡ç®—åŠ é€Ÿæ¯”
        speedup = uw_time / your_time if your_time > 0 else 0
        
        benchmark_results[problem_name] = {
            'problem_size': A.shape[0],
            'description': description,
            'your_solver_time': your_time,
            'underworld_estimated_time': uw_time,
            'speedup': speedup,
            'residual_norm': residual
        }
        
        print(f"   ä½ çš„æ±‚è§£å™¨: {your_time:.4f}s")
        print(f"   Underworldä¼°è®¡: {uw_time:.4f}s")
        print(f"   åŠ é€Ÿæ¯”: {speedup:.2f}x")
        print(f"   æ®‹å·®èŒƒæ•°: {residual:.2e}")
    
    # è¾“å‡ºæ€»ç»“
    print("\nğŸ“Š åŸºå‡†æµ‹è¯•ç»“æœæ€»ç»“")
    print("=" * 60)
    
    total_speedup = 0
    for problem_name, results in benchmark_results.items():
        print(f"{problem_name:20s}: åŠ é€Ÿæ¯” {results['speedup']:6.2f}x")
        total_speedup += results['speedup']
    
    avg_speedup = total_speedup / len(benchmark_results)
    print(f"\nğŸ† å¹³å‡åŠ é€Ÿæ¯”: {avg_speedup:.2f}x")
    
    return benchmark_results


def save_demo_results(results_dict):
    """ä¿å­˜æ¼”ç¤ºç»“æœ"""
    output_file = "underworld_surpassing_demo_results.json"
    
    # æ·»åŠ æ—¶é—´æˆ³
    results_dict['timestamp'] = time.time()
    results_dict['demo_info'] = {
        'title': 'è¶…è¶ŠUnderworldçš„å¹¶è¡Œæ±‚è§£å™¨æ¼”ç¤º',
        'description': 'å±•ç¤ºé€šä¿¡ä¼˜åŒ–ã€æ™ºèƒ½è´Ÿè½½å‡è¡¡ã€å¼‚æ„è®¡ç®—ã€è‡ªé€‚åº”ç®—æ³•é€‰æ‹©ç­‰æ ¸å¿ƒåŠŸèƒ½',
        'version': '1.0.0'
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results_dict, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ æ¼”ç¤ºç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    return output_file


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ è¶…è¶ŠUnderworldçš„å¹¶è¡Œæ±‚è§£å™¨æ¼”ç¤º")
    print("=" * 60)
    print("æœ¬æ¼”ç¤ºå°†å±•ç¤ºä»¥ä¸‹æ ¸å¿ƒçªç ´åŠŸèƒ½:")
    print("1. ğŸš€ é€šä¿¡ä¼˜åŒ–: éé˜»å¡é€šä¿¡+è®¡ç®—é‡å +è‡ªé€‚åº”é€šä¿¡æ¨¡å¼")
    print("2. âš–ï¸ æ™ºèƒ½è´Ÿè½½å‡è¡¡: MLé¢„æµ‹+åŠ¨æ€è´Ÿè½½è¿ç§»")
    print("3. ğŸ–¥ï¸ å¼‚æ„è®¡ç®—: MPI+GPU+OpenMPæ··åˆæ¶æ„")
    print("4. ğŸ§  ç®—æ³•é€‚åº”æ€§: é—®é¢˜æ„ŸçŸ¥çš„è‡ªé€‚åº”æ±‚è§£ç­–ç•¥")
    print("5. ğŸ† æ€§èƒ½åŸºå‡†æµ‹è¯•: ä¸Underworldçš„æ€§èƒ½å¯¹æ¯”")
    print("=" * 60)
    
    # å­˜å‚¨æ‰€æœ‰æ¼”ç¤ºç»“æœ
    demo_results = {}
    
    try:
        # 1. é€šä¿¡ä¼˜åŒ–æ¼”ç¤º
        comm_schedule = demonstrate_communication_optimization()
        demo_results['communication_optimization'] = comm_schedule
        
        # 2. è´Ÿè½½å‡è¡¡æ¼”ç¤º
        load_balance_result = demonstrate_load_balancing()
        demo_results['load_balancing'] = load_balance_result
        
        # 3. å¼‚æ„è®¡ç®—æ¼”ç¤º
        heterogeneous_result = demonstrate_heterogeneous_computing()
        demo_results['heterogeneous_computing'] = {
            'gpu_available': heterogeneous_result.gpu_available,
            'openmp_available': heterogeneous_result.openmp_available,
            'gpu_performance_count': len(heterogeneous_result.gpu_performance),
            'cpu_performance_count': len(heterogeneous_result.cpu_performance)
        }
        
        # 4. è‡ªé€‚åº”æ±‚è§£å™¨é€‰æ‹©æ¼”ç¤º
        solver_selection_result = demonstrate_adaptive_solver_selection()
        demo_results['adaptive_solver_selection'] = {
            'problem_classifier_available': True,
            'performance_database_size': len(solver_selection_result.solver_performance_db)
        }
        
        # 5. å…¨é¢æ€§èƒ½åŸºå‡†æµ‹è¯•
        benchmark_results = run_comprehensive_benchmark()
        demo_results['benchmark_results'] = benchmark_results
        
        # ä¿å­˜ç»“æœ
        output_file = save_demo_results(demo_results)
        
        print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
        print(f"   æ‰€æœ‰åŠŸèƒ½æ¼”ç¤ºæˆåŠŸ")
        print(f"   ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # æ€§èƒ½æ€»ç»“
        if 'benchmark_results' in demo_results:
            avg_speedup = np.mean([r['speedup'] for r in demo_results['benchmark_results'].values()])
            print(f"\nğŸ“ˆ æ€§èƒ½æ€»ç»“:")
            print(f"   å¹³å‡åŠ é€Ÿæ¯”: {avg_speedup:.2f}x")
            print(f"   æµ‹è¯•é—®é¢˜æ•°: {len(demo_results['benchmark_results'])}")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    return demo_results


if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    results = main()
    
    print(f"\nğŸ”š æ¼”ç¤ºç»“æŸ")
    print("æ„Ÿè°¢ä½¿ç”¨è¶…è¶ŠUnderworldçš„å¹¶è¡Œæ±‚è§£å™¨ï¼")
