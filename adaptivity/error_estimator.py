"""
è¯¯å·®ä¼°è®¡å™¨å®ç°
"""

import numpy as np
from typing import Dict, List, Tuple, Optional, Union
from dataclasses import dataclass
from abc import ABC, abstractmethod
import scipy.sparse as sp


@dataclass
class ErrorIndicator:
    """è¯¯å·®æŒ‡ç¤ºå™¨"""
    element_id: int
    error_value: float
    error_type: str  # 'residual', 'recovery', 'gradient', 'hessian'
    refinement_flag: bool = False
    
    def __post_init__(self):
        if self.error_value < 0:
            raise ValueError("è¯¯å·®å€¼ä¸èƒ½ä¸ºè´Ÿæ•°")


class BaseErrorEstimator(ABC):
    """è¯¯å·®ä¼°è®¡å™¨åŸºç±»"""
    
    def __init__(self, tolerance: float = 1e-6):
        self.tolerance = tolerance
        self.error_indicators: List[ErrorIndicator] = []
    
    @abstractmethod
    def compute_error(self, solution: np.ndarray, mesh_data: Dict) -> List[ErrorIndicator]:
        """è®¡ç®—è¯¯å·®"""
        pass
    
    @abstractmethod
    def compute_global_error(self, error_indicators: List[ErrorIndicator]) -> float:
        """è®¡ç®—å…¨å±€è¯¯å·®"""
        pass
    
    def estimate_convergence_rate(self, error_history: List[float]) -> float:
        """ä¼°è®¡æ”¶æ•›ç‡"""
        if len(error_history) < 2:
            return 0.0
        
        # ä½¿ç”¨æœ€å°äºŒä¹˜æ³•ä¼°è®¡æ”¶æ•›ç‡
        log_errors = np.log(error_history)
        n = len(log_errors)
        x = np.arange(n)
        
        # çº¿æ€§æ‹Ÿåˆ
        A = np.vstack([x, np.ones(n)]).T
        slope, _ = np.linalg.lstsq(A, log_errors, rcond=None)[0]
        
        return -slope  # æ”¶æ•›ç‡é€šå¸¸ä¸ºè´Ÿå€¼


class ResidualErrorEstimator(BaseErrorEstimator):
    """æ®‹å·®è¯¯å·®ä¼°è®¡å™¨"""
    
    def __init__(self, tolerance: float = 1e-6):
        super().__init__(tolerance)
    
    def compute_residual(self, solution: np.ndarray, mesh_data: Dict) -> np.ndarray:
        """è®¡ç®—æ®‹å·®"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“çš„PDEè®¡ç®—æ®‹å·®
        # ç®€åŒ–å®ç°ï¼šå‡è®¾æ®‹å·®ä¸ºè§£çš„æ¢¯åº¦
        if solution.ndim == 1:
            # 1Dæƒ…å†µ
            residual = np.gradient(solution)
        else:
            # 2D/3Dæƒ…å†µ
            residual = np.zeros_like(solution)
            for i in range(solution.ndim):
                residual += np.gradient(solution, axis=i) ** 2
            residual = np.sqrt(residual)
        
        return residual
    
    def compute_error(self, solution: np.ndarray, mesh_data: Dict) -> List[ErrorIndicator]:
        """è®¡ç®—æ®‹å·®è¯¯å·®"""
        residual = self.compute_residual(solution, mesh_data)
        
        # è®¡ç®—æ¯ä¸ªå•å…ƒçš„è¯¯å·®
        elements = mesh_data.get('elements', [])
        error_indicators = []
        
        for i, element in enumerate(elements):
            # è®¡ç®—å•å…ƒå†…çš„æ®‹å·®è¯¯å·®
            element_nodes = element['nodes']
            element_residual = residual[element_nodes]
            
            # ä½¿ç”¨L2èŒƒæ•°è®¡ç®—è¯¯å·®
            error_value = np.sqrt(np.mean(element_residual ** 2))
            
            # åˆ›å»ºè¯¯å·®æŒ‡ç¤ºå™¨
            indicator = ErrorIndicator(
                element_id=i,
                error_value=error_value,
                error_type='residual',
                refinement_flag=error_value > self.tolerance
            )
            error_indicators.append(indicator)
        
        self.error_indicators = error_indicators
        return error_indicators
    
    def compute_global_error(self, error_indicators: List[ErrorIndicator]) -> float:
        """è®¡ç®—å…¨å±€è¯¯å·®"""
        if not error_indicators:
            return 0.0
        
        error_values = [indicator.error_value for indicator in error_indicators]
        return np.sqrt(np.sum(np.array(error_values) ** 2))


class RecoveryErrorEstimator(BaseErrorEstimator):
    """æ¢å¤è¯¯å·®ä¼°è®¡å™¨ï¼ˆZienkiewicz-Zhuæ–¹æ³•ï¼‰"""
    
    def __init__(self, tolerance: float = 1e-6):
        super().__init__(tolerance)
    
    def compute_recovered_gradient(self, solution: np.ndarray, mesh_data: Dict) -> np.ndarray:
        """è®¡ç®—æ¢å¤æ¢¯åº¦"""
        # ä½¿ç”¨Zienkiewicz-Zhuæ–¹æ³•è®¡ç®—æ¢å¤æ¢¯åº¦
        nodes = mesh_data.get('nodes', [])
        elements = mesh_data.get('elements', [])
        
        if not nodes or not elements:
            return np.zeros_like(solution)
        
        # åˆå§‹åŒ–æ¢å¤æ¢¯åº¦
        recovered_gradient = np.zeros((len(nodes), solution.ndim))
        node_weights = np.zeros(len(nodes))
        
        # å¯¹æ¯ä¸ªå•å…ƒè®¡ç®—æ¢¯åº¦å¹¶åˆ†é…åˆ°èŠ‚ç‚¹
        for element in elements:
            element_nodes = element['nodes']
            element_coords = np.array([nodes[i] for i in element_nodes])
            element_solution = solution[element_nodes]
            
            # è®¡ç®—å•å…ƒæ¢¯åº¦
            if len(element_nodes) == 3:  # ä¸‰è§’å½¢
                gradient = self._compute_triangle_gradient(element_coords, element_solution)
            elif len(element_nodes) == 4:  # å››è¾¹å½¢
                gradient = self._compute_quadrilateral_gradient(element_coords, element_solution)
            else:
                continue
            
            # å°†æ¢¯åº¦åˆ†é…åˆ°èŠ‚ç‚¹
            for i, node_id in enumerate(element_nodes):
                recovered_gradient[node_id] += gradient
                node_weights[node_id] += 1
        
        # å¹³å‡åŒ–
        for i in range(len(nodes)):
            if node_weights[i] > 0:
                recovered_gradient[i] /= node_weights[i]
        
        return recovered_gradient
    
    def _compute_triangle_gradient(self, coords: np.ndarray, solution: np.ndarray) -> np.ndarray:
        """è®¡ç®—ä¸‰è§’å½¢å•å…ƒçš„æ¢¯åº¦"""
        # ä½¿ç”¨æœ‰é™å·®åˆ†è®¡ç®—æ¢¯åº¦
        x1, y1 = coords[0]
        x2, y2 = coords[1]
        x3, y3 = coords[2]
        
        # è®¡ç®—é¢ç§¯
        area = 0.5 * abs((x2 - x1) * (y3 - y1) - (x3 - x1) * (y2 - y1))
        
        if area < 1e-12:
            return np.zeros(2)
        
        # è®¡ç®—æ¢¯åº¦
        dx = (solution[1] - solution[0]) * (y3 - y1) - (solution[2] - solution[0]) * (y2 - y1)
        dy = (solution[2] - solution[0]) * (x2 - x1) - (solution[1] - solution[0]) * (x3 - x1)
        
        gradient = np.array([dx, dy]) / (2 * area)
        return gradient
    
    def _compute_quadrilateral_gradient(self, coords: np.ndarray, solution: np.ndarray) -> np.ndarray:
        """è®¡ç®—å››è¾¹å½¢å•å…ƒçš„æ¢¯åº¦"""
        # ç®€åŒ–ä¸ºä¸¤ä¸ªä¸‰è§’å½¢çš„ç»„åˆ
        # è¿™é‡Œå¯ä»¥å®ç°æ›´ç²¾ç¡®çš„å››è¾¹å½¢æ¢¯åº¦è®¡ç®—
        return np.zeros(2)
    
    def compute_error(self, solution: np.ndarray, mesh_data: Dict) -> List[ErrorIndicator]:
        """è®¡ç®—æ¢å¤è¯¯å·®"""
        # è®¡ç®—æ•°å€¼æ¢¯åº¦
        numerical_gradient = self._compute_numerical_gradient(solution, mesh_data)
        
        # è®¡ç®—æ¢å¤æ¢¯åº¦
        recovered_gradient = self.compute_recovered_gradient(solution, mesh_data)
        
        # è®¡ç®—è¯¯å·®
        elements = mesh_data.get('elements', [])
        error_indicators = []
        
        for i, element in enumerate(elements):
            element_nodes = element['nodes']
            
            # è®¡ç®—å•å…ƒå†…çš„æ¢¯åº¦è¯¯å·®
            element_numerical = numerical_gradient[element_nodes]
            element_recovered = recovered_gradient[element_nodes]
            
            # è®¡ç®—è¯¯å·®
            error = element_recovered - element_numerical
            error_value = np.sqrt(np.mean(error ** 2))
            
            indicator = ErrorIndicator(
                element_id=i,
                error_value=error_value,
                error_type='recovery',
                refinement_flag=error_value > self.tolerance
            )
            error_indicators.append(indicator)
        
        self.error_indicators = error_indicators
        return error_indicators
    
    def _compute_numerical_gradient(self, solution: np.ndarray, mesh_data: Dict) -> np.ndarray:
        """è®¡ç®—æ•°å€¼æ¢¯åº¦"""
        # ç®€åŒ–å®ç°ï¼šä½¿ç”¨æœ‰é™å·®åˆ†
        if solution.ndim == 1:
            return np.gradient(solution)
        else:
            gradient = np.zeros((len(solution), solution.ndim))
            for i in range(solution.ndim):
                gradient[:, i] = np.gradient(solution, axis=i)
            return gradient
    
    def compute_global_error(self, error_indicators: List[ErrorIndicator]) -> float:
        """è®¡ç®—å…¨å±€è¯¯å·®"""
        if not error_indicators:
            return 0.0
        
        error_values = [indicator.error_value for indicator in error_indicators]
        return np.sqrt(np.sum(np.array(error_values) ** 2))


class StrainRateErrorEstimator(BaseErrorEstimator):
    """åŸºäºåº”å˜ç‡çš„è¯¯å·®ä¼°è®¡å™¨ - é€‚ç”¨äºåœ°è´¨åŠ›å­¦é—®é¢˜"""
    
    def __init__(self, tolerance: float = 1e-6, strain_rate_threshold: float = 1e-6):
        super().__init__(tolerance)
        self.strain_rate_threshold = strain_rate_threshold
    
    def compute_strain_rate(self, displacement: np.ndarray, mesh_data: Dict) -> np.ndarray:
        """è®¡ç®—åº”å˜ç‡"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“çš„æœ‰é™å…ƒå®ç°æ¥è®¡ç®—åº”å˜ç‡
        # ç®€åŒ–å®ç°ï¼šåŸºäºä½ç§»æ¢¯åº¦
        
        if displacement.ndim == 1:
            # 1Dæƒ…å†µ
            strain_rate = np.gradient(displacement)
        else:
            # 2D/3Dæƒ…å†µï¼šè®¡ç®—ä½ç§»æ¢¯åº¦
            strain_rate = np.zeros_like(displacement)
            
            # è·å–ç½‘æ ¼ä¿¡æ¯
            elements = mesh_data.get('elements', [])
            nodes = mesh_data.get('nodes', [])
            
            for element in elements:
                element_nodes = element.get('nodes', [])
                if len(element_nodes) >= 2:
                    # è®¡ç®—å•å…ƒå†…çš„åº”å˜ç‡
                    element_displacement = displacement[element_nodes]
                    element_coords = nodes[element_nodes]
                    
                    # ç®€åŒ–çš„åº”å˜ç‡è®¡ç®—
                    if len(element_nodes) == 2:  # 1Då•å…ƒ
                        strain_rate[element_nodes] = np.gradient(element_displacement)
                    else:  # 2D/3Då•å…ƒ
                        # è¿™é‡Œéœ€è¦æ›´å¤æ‚çš„åº”å˜ç‡è®¡ç®—
                        # ç®€åŒ–ï¼šä½¿ç”¨ä½ç§»çš„æ¢¯åº¦
                        for i in range(displacement.shape[1]):
                            strain_rate[element_nodes, i] = np.gradient(element_displacement[:, i])
        
        return strain_rate
    
    def compute_error(self, solution: np.ndarray, mesh_data: Dict) -> List[ErrorIndicator]:
        """è®¡ç®—åŸºäºåº”å˜ç‡çš„è¯¯å·®"""
        # å‡è®¾solutionåŒ…å«ä½ç§»åœº
        displacement = solution
        
        # è®¡ç®—åº”å˜ç‡
        strain_rate = self.compute_strain_rate(displacement, mesh_data)
        
        # è®¡ç®—åº”å˜ç‡å¹…å€¼
        if strain_rate.ndim > 1:
            strain_rate_magnitude = np.sqrt(np.sum(strain_rate**2, axis=1))
        else:
            strain_rate_magnitude = np.abs(strain_rate)
        
        # è®¡ç®—æ¯ä¸ªå•å…ƒçš„è¯¯å·®
        elements = mesh_data.get('elements', [])
        error_indicators = []
        
        for i, element in enumerate(elements):
            element_nodes = element.get('nodes', [])
            if element_nodes:
                # è®¡ç®—å•å…ƒå†…çš„å¹³å‡åº”å˜ç‡
                element_strain_rate = strain_rate_magnitude[element_nodes]
                error_value = np.mean(element_strain_rate)
                
                # åˆ›å»ºè¯¯å·®æŒ‡ç¤ºå™¨
                indicator = ErrorIndicator(
                    element_id=i,
                    error_value=error_value,
                    error_type="strain_rate",
                    refinement_flag=error_value > self.strain_rate_threshold
                )
                error_indicators.append(indicator)
        
        return error_indicators
    
    def compute_global_error(self, error_indicators: List[ErrorIndicator]) -> float:
        """è®¡ç®—å…¨å±€è¯¯å·®"""
        if not error_indicators:
            return 0.0
        
        # ä½¿ç”¨L2èŒƒæ•°è®¡ç®—å…¨å±€è¯¯å·®
        error_values = [indicator.error_value for indicator in error_indicators]
        return np.sqrt(np.mean(np.array(error_values) ** 2))
    
    def get_refinement_candidates(self, error_indicators: List[ErrorIndicator], 
                                refinement_ratio: float = 0.3) -> List[int]:
        """è·å–éœ€è¦ç»†åŒ–çš„å•å…ƒå€™é€‰"""
        if not error_indicators:
            return []
        
        # æŒ‰è¯¯å·®å€¼æ’åº
        sorted_indicators = sorted(error_indicators, key=lambda x: x.error_value, reverse=True)
        
        # é€‰æ‹©è¯¯å·®æœ€å¤§çš„å•å…ƒè¿›è¡Œç»†åŒ–
        n_refine = int(refinement_ratio * len(sorted_indicators))
        candidates = [indicator.element_id for indicator in sorted_indicators[:n_refine]]
        
        return candidates
    
    def get_coarsening_candidates(self, error_indicators: List[ErrorIndicator],
                                coarsening_ratio: float = 0.2) -> List[int]:
        """è·å–å¯ä»¥ç²—åŒ–çš„å•å…ƒå€™é€‰"""
        if not error_indicators:
            return []
        
        # æŒ‰è¯¯å·®å€¼æ’åº
        sorted_indicators = sorted(error_indicators, key=lambda x: x.error_value)
        
        # é€‰æ‹©è¯¯å·®æœ€å°çš„å•å…ƒè¿›è¡Œç²—åŒ–
        n_coarsen = int(coarsening_ratio * len(sorted_indicators))
        candidates = [indicator.element_id for indicator in sorted_indicators[:n_coarsen]]
        
        return candidates


class GradientErrorEstimator(BaseErrorEstimator):
    """åŸºäºæ¢¯åº¦çš„è¯¯å·®ä¼°è®¡å™¨"""
    
    def __init__(self, tolerance: float = 1e-6, gradient_threshold: float = 1e-3):
        super().__init__(tolerance)
        self.gradient_threshold = gradient_threshold
    
    def compute_gradient(self, solution: np.ndarray, mesh_data: Dict) -> np.ndarray:
        """è®¡ç®—è§£çš„æ¢¯åº¦"""
        if solution.ndim == 1:
            # 1Dæƒ…å†µ
            gradient = np.gradient(solution)
        else:
            # 2D/3Dæƒ…å†µ
            gradient = np.zeros_like(solution)
            for i in range(solution.shape[1]):
                gradient[:, i] = np.gradient(solution[:, i])
        
        return gradient
    
    def compute_error(self, solution: np.ndarray, mesh_data: Dict) -> List[ErrorIndicator]:
        """è®¡ç®—åŸºäºæ¢¯åº¦çš„è¯¯å·®"""
        gradient = self.compute_gradient(solution, mesh_data)
        
        # è®¡ç®—æ¢¯åº¦å¹…å€¼
        if gradient.ndim > 1:
            gradient_magnitude = np.sqrt(np.sum(gradient**2, axis=1))
        else:
            gradient_magnitude = np.abs(gradient)
        
        # è®¡ç®—æ¯ä¸ªå•å…ƒçš„è¯¯å·®
        elements = mesh_data.get('elements', [])
        error_indicators = []
        
        for i, element in enumerate(elements):
            element_nodes = element.get('nodes', [])
            if element_nodes:
                # è®¡ç®—å•å…ƒå†…çš„å¹³å‡æ¢¯åº¦
                element_gradient = gradient_magnitude[element_nodes]
                error_value = np.mean(element_gradient)
                
                # åˆ›å»ºè¯¯å·®æŒ‡ç¤ºå™¨
                indicator = ErrorIndicator(
                    element_id=i,
                    error_value=error_value,
                    error_type="gradient",
                    refinement_flag=error_value > self.gradient_threshold
                )
                error_indicators.append(indicator)
        
        return error_indicators
    
    def compute_global_error(self, error_indicators: List[ErrorIndicator]) -> float:
        """è®¡ç®—å…¨å±€è¯¯å·®"""
        if not error_indicators:
            return 0.0
        
        # ä½¿ç”¨L2èŒƒæ•°è®¡ç®—å…¨å±€è¯¯å·®
        error_values = [indicator.error_value for indicator in error_indicators]
        return np.sqrt(np.mean(np.array(error_values) ** 2))


class HessianErrorEstimator(BaseErrorEstimator):
    """åŸºäºHessiançš„è¯¯å·®ä¼°è®¡å™¨ - é€‚ç”¨äºé«˜é˜¶ç²¾åº¦é—®é¢˜"""
    
    def __init__(self, tolerance: float = 1e-6, hessian_threshold: float = 1e-2):
        super().__init__(tolerance)
        self.hessian_threshold = hessian_threshold
    
    def compute_hessian(self, solution: np.ndarray, mesh_data: Dict) -> np.ndarray:
        """è®¡ç®—è§£çš„HessiançŸ©é˜µ"""
        if solution.ndim == 1:
            # 1Dæƒ…å†µï¼šäºŒé˜¶å¯¼æ•°
            hessian = np.gradient(np.gradient(solution))
        else:
            # 2D/3Dæƒ…å†µï¼šéœ€è¦è®¡ç®—æ··åˆåå¯¼æ•°
            # ç®€åŒ–å®ç°ï¼šåªè®¡ç®—å¯¹è§’é¡¹
            hessian = np.zeros_like(solution)
            for i in range(solution.shape[1]):
                hessian[:, i] = np.gradient(np.gradient(solution[:, i]))
        
        return hessian
    
    def compute_error(self, solution: np.ndarray, mesh_data: Dict) -> List[ErrorIndicator]:
        """è®¡ç®—åŸºäºHessiançš„è¯¯å·®"""
        hessian = self.compute_hessian(solution, mesh_data)
        
        # è®¡ç®—Hessiançš„FrobeniusèŒƒæ•°
        if hessian.ndim > 1:
            hessian_norm = np.sqrt(np.sum(hessian**2, axis=1))
        else:
            hessian_norm = np.abs(hessian)
        
        # è®¡ç®—æ¯ä¸ªå•å…ƒçš„è¯¯å·®
        elements = mesh_data.get('elements', [])
        error_indicators = []
        
        for i, element in enumerate(elements):
            element_nodes = element.get('nodes', [])
            if element_nodes:
                # è®¡ç®—å•å…ƒå†…çš„å¹³å‡HessianèŒƒæ•°
                element_hessian = hessian_norm[element_nodes]
                error_value = np.mean(element_hessian)
                
                # åˆ›å»ºè¯¯å·®æŒ‡ç¤ºå™¨
                indicator = ErrorIndicator(
                    element_id=i,
                    error_value=error_value,
                    error_type="hessian",
                    refinement_flag=error_value > self.hessian_threshold
                )
                error_indicators.append(indicator)
        
        return error_indicators
    
    def compute_global_error(self, error_indicators: List[ErrorIndicator]) -> float:
        """è®¡ç®—å…¨å±€è¯¯å·®"""
        if not error_indicators:
            return 0.0
        
        # ä½¿ç”¨L2èŒƒæ•°è®¡ç®—å…¨å±€è¯¯å·®
        error_values = [indicator.error_value for indicator in error_indicators]
        return np.sqrt(np.mean(np.array(error_values) ** 2))


class AdaptiveErrorEstimator(BaseErrorEstimator):
    """è‡ªé€‚åº”è¯¯å·®ä¼°è®¡å™¨ - æ ¹æ®é—®é¢˜ç‰¹æ€§é€‰æ‹©æœ€ä½³ä¼°è®¡æ–¹æ³•"""
    
    def __init__(self, tolerance: float = 1e-6):
        super().__init__(tolerance)
        self.estimators = {
            'residual': ResidualErrorEstimator(tolerance),
            'strain_rate': StrainRateErrorEstimator(tolerance),
            'gradient': GradientErrorEstimator(tolerance),
            'hessian': HessianErrorEstimator(tolerance)
        }
        self.current_estimator = 'residual'
    
    def select_estimator(self, problem_features: Dict) -> str:
        """æ ¹æ®é—®é¢˜ç‰¹æ€§é€‰æ‹©æœ€ä½³è¯¯å·®ä¼°è®¡å™¨"""
        problem_type = problem_features.get('type', 'general')
        
        if problem_type == 'geomechanics':
            # åœ°è´¨åŠ›å­¦é—®é¢˜ï¼šä¼˜å…ˆä½¿ç”¨åº”å˜ç‡ä¼°è®¡å™¨
            return 'strain_rate'
        elif problem_type == 'fluid_dynamics':
            # æµä½“åŠ¨åŠ›å­¦ï¼šä¼˜å…ˆä½¿ç”¨æ¢¯åº¦ä¼°è®¡å™¨
            return 'gradient'
        elif problem_type == 'high_order':
            # é«˜é˜¶ç²¾åº¦é—®é¢˜ï¼šä½¿ç”¨Hessianä¼°è®¡å™¨
            return 'hessian'
        else:
            # ä¸€èˆ¬é—®é¢˜ï¼šä½¿ç”¨æ®‹å·®ä¼°è®¡å™¨
            return 'residual'
    
    def compute_error(self, solution: np.ndarray, mesh_data: Dict, 
                     problem_features: Dict = None) -> List[ErrorIndicator]:
        """è®¡ç®—è¯¯å·®"""
        if problem_features:
            self.current_estimator = self.select_estimator(problem_features)
        
        estimator = self.estimators[self.current_estimator]
        return estimator.compute_error(solution, mesh_data)
    
    def compute_global_error(self, error_indicators: List[ErrorIndicator]) -> float:
        """è®¡ç®—å…¨å±€è¯¯å·®"""
        estimator = self.estimators[self.current_estimator]
        return estimator.compute_global_error(error_indicators)
    
    def get_refinement_candidates(self, error_indicators: List[ErrorIndicator],
                                refinement_ratio: float = 0.3) -> List[int]:
        """è·å–éœ€è¦ç»†åŒ–çš„å•å…ƒå€™é€‰"""
        if self.current_estimator == 'strain_rate':
            estimator = self.estimators['strain_rate']
            return estimator.get_refinement_candidates(error_indicators, refinement_ratio)
        else:
            # é»˜è®¤å®ç°
            if not error_indicators:
                return []
            
            sorted_indicators = sorted(error_indicators, key=lambda x: x.error_value, reverse=True)
            n_refine = int(refinement_ratio * len(sorted_indicators))
            return [indicator.element_id for indicator in sorted_indicators[:n_refine]]


# å·¥å‚å‡½æ•°
def create_error_estimator(estimator_type: str = 'adaptive', **kwargs) -> BaseErrorEstimator:
    """åˆ›å»ºè¯¯å·®ä¼°è®¡å™¨"""
    if estimator_type == 'residual':
        return ResidualErrorEstimator(**kwargs)
    elif estimator_type == 'recovery':
        return RecoveryErrorEstimator(**kwargs)
    elif estimator_type == 'gradient':
        return GradientErrorEstimator(**kwargs)
    elif estimator_type == 'adaptive':
        return AdaptiveErrorEstimator(**kwargs)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¯¯å·®ä¼°è®¡å™¨ç±»å‹: {estimator_type}")


def demo_error_estimation():
    """æ¼”ç¤ºè¯¯å·®ä¼°è®¡åŠŸèƒ½ - ä¼˜åŒ–ç‰ˆæœ¬"""
    print("ğŸ“Š è¯¯å·®ä¼°è®¡æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    n_elements = 100
    solution = np.random.rand(n_elements)
    mesh_data = {
        'elements': [{'nodes': [i, i+1]} for i in range(n_elements-1)],
        'nodes': [[i, 0] for i in range(n_elements)],
        'element_types': ['line'] * (n_elements-1)
    }
    problem_data = {
        'material_properties': {'E': 1.0, 'nu': 0.3},
        'boundary_conditions': {'dirichlet': [0, n_elements-1]}
    }
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„è¯¯å·®ä¼°è®¡å™¨
    estimators = {
        'residual_energy': ResidualErrorEstimator(tolerance=1e-3),
        'residual_l2': ResidualErrorEstimator(tolerance=1e-3),
        'recovery_spr': RecoveryErrorEstimator(tolerance=1e-3),
        'adaptive': AdaptiveErrorEstimator(tolerance=1e-3, weights={'residual': 0.4, 'recovery': 0.4, 'gradient': 0.2}),
        'gradient': GradientErrorEstimator(tolerance=1e-3)
    }
    
    for name, estimator in estimators.items():
        print(f"\nğŸ” æµ‹è¯• {name} è¯¯å·®ä¼°è®¡å™¨...")
        
        try:
            error_indicators = estimator.compute_error(solution, mesh_data)
            global_error = estimator.compute_global_error(error_indicators)
            
            print(f"   è®¡ç®—æ—¶é—´: {estimator.computation_time:.4f} ç§’")
            print(f"   å¹³å‡è¯¯å·®: {estimator.error_history[-1]:.6f}")
            print(f"   å…¨å±€è¯¯å·®: {global_error:.6f}")
            print(f"   éœ€è¦ç»†åŒ–çš„å•å…ƒæ•°: {np.sum([i.refinement_flag for i in error_indicators])}")
            
        except Exception as e:
            print(f"   âŒ è¯¯å·®ä¼°è®¡å¤±è´¥: {e}")
    
    print("\nâœ… è¯¯å·®ä¼°è®¡æ¼”ç¤ºå®Œæˆ!")


if __name__ == "__main__":
    demo_error_estimation() 