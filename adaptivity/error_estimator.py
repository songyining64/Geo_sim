"""
è¯¯å·®ä¼°è®¡å™¨å®ç°
"""

import numpy as np
from typing import Dict, List, Tuple, Optional, Union
from dataclasses import dataclass
from abc import ABC, abstractmethod
import scipy.sparse as sp


@dataclass
class ErrorIndicator:
    """è¯¯å·®æŒ‡ç¤ºå™¨"""
    element_id: int
    error_value: float
    error_type: str  # 'residual', 'recovery', 'gradient', 'hessian'
    refinement_flag: bool = False
    
    def __post_init__(self):
        if self.error_value < 0:
            raise ValueError("è¯¯å·®å€¼ä¸èƒ½ä¸ºè´Ÿæ•°")


class BaseErrorEstimator(ABC):
    """è¯¯å·®ä¼°è®¡å™¨åŸºç±»"""
    
    def __init__(self, tolerance: float = 1e-6):
        self.tolerance = tolerance
        self.error_indicators: List[ErrorIndicator] = []
    
    @abstractmethod
    def compute_error(self, solution: np.ndarray, mesh_data: Dict) -> List[ErrorIndicator]:
        """è®¡ç®—è¯¯å·®"""
        pass
    
    @abstractmethod
    def compute_global_error(self, error_indicators: List[ErrorIndicator]) -> float:
        """è®¡ç®—å…¨å±€è¯¯å·®"""
        pass
    
    def estimate_convergence_rate(self, error_history: List[float]) -> float:
        """ä¼°è®¡æ”¶æ•›ç‡"""
        if len(error_history) < 2:
            return 0.0
        
        # ä½¿ç”¨æœ€å°äºŒä¹˜æ³•ä¼°è®¡æ”¶æ•›ç‡
        log_errors = np.log(error_history)
        n = len(log_errors)
        x = np.arange(n)
        
        # çº¿æ€§æ‹Ÿåˆ
        A = np.vstack([x, np.ones(n)]).T
        slope, _ = np.linalg.lstsq(A, log_errors, rcond=None)[0]
        
        return -slope  # æ”¶æ•›ç‡é€šå¸¸ä¸ºè´Ÿå€¼


class ResidualErrorEstimator(BaseErrorEstimator):
    """æ®‹å·®è¯¯å·®ä¼°è®¡å™¨"""
    
    def __init__(self, tolerance: float = 1e-6):
        super().__init__(tolerance)
    
    def compute_residual(self, solution: np.ndarray, mesh_data: Dict) -> np.ndarray:
        """è®¡ç®—æ®‹å·®"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“çš„PDEè®¡ç®—æ®‹å·®
        # ç®€åŒ–å®ç°ï¼šå‡è®¾æ®‹å·®ä¸ºè§£çš„æ¢¯åº¦
        if solution.ndim == 1:
            # 1Dæƒ…å†µ
            residual = np.gradient(solution)
        else:
            # 2D/3Dæƒ…å†µ
            residual = np.zeros_like(solution)
            for i in range(solution.ndim):
                residual += np.gradient(solution, axis=i) ** 2
            residual = np.sqrt(residual)
        
        return residual
    
    def compute_error(self, solution: np.ndarray, mesh_data: Dict) -> List[ErrorIndicator]:
        """è®¡ç®—æ®‹å·®è¯¯å·®"""
        residual = self.compute_residual(solution, mesh_data)
        
        # è®¡ç®—æ¯ä¸ªå•å…ƒçš„è¯¯å·®
        elements = mesh_data.get('elements', [])
        error_indicators = []
        
        for i, element in enumerate(elements):
            # è®¡ç®—å•å…ƒå†…çš„æ®‹å·®è¯¯å·®
            element_nodes = element['nodes']
            element_residual = residual[element_nodes]
            
            # ä½¿ç”¨L2èŒƒæ•°è®¡ç®—è¯¯å·®
            error_value = np.sqrt(np.mean(element_residual ** 2))
            
            # åˆ›å»ºè¯¯å·®æŒ‡ç¤ºå™¨
            indicator = ErrorIndicator(
                element_id=i,
                error_value=error_value,
                error_type='residual',
                refinement_flag=error_value > self.tolerance
            )
            error_indicators.append(indicator)
        
        self.error_indicators = error_indicators
        return error_indicators
    
    def compute_global_error(self, error_indicators: List[ErrorIndicator]) -> float:
        """è®¡ç®—å…¨å±€è¯¯å·®"""
        if not error_indicators:
            return 0.0
        
        error_values = [indicator.error_value for indicator in error_indicators]
        return np.sqrt(np.sum(np.array(error_values) ** 2))


class RecoveryErrorEstimator(BaseErrorEstimator):
    """æ¢å¤è¯¯å·®ä¼°è®¡å™¨ï¼ˆZienkiewicz-Zhuæ–¹æ³•ï¼‰"""
    
    def __init__(self, tolerance: float = 1e-6):
        super().__init__(tolerance)
    
    def compute_recovered_gradient(self, solution: np.ndarray, mesh_data: Dict) -> np.ndarray:
        """è®¡ç®—æ¢å¤æ¢¯åº¦"""
        # ä½¿ç”¨Zienkiewicz-Zhuæ–¹æ³•è®¡ç®—æ¢å¤æ¢¯åº¦
        nodes = mesh_data.get('nodes', [])
        elements = mesh_data.get('elements', [])
        
        if not nodes or not elements:
            return np.zeros_like(solution)
        
        # åˆå§‹åŒ–æ¢å¤æ¢¯åº¦
        recovered_gradient = np.zeros((len(nodes), solution.ndim))
        node_weights = np.zeros(len(nodes))
        
        # å¯¹æ¯ä¸ªå•å…ƒè®¡ç®—æ¢¯åº¦å¹¶åˆ†é…åˆ°èŠ‚ç‚¹
        for element in elements:
            element_nodes = element['nodes']
            element_coords = np.array([nodes[i] for i in element_nodes])
            element_solution = solution[element_nodes]
            
            # è®¡ç®—å•å…ƒæ¢¯åº¦
            if len(element_nodes) == 3:  # ä¸‰è§’å½¢
                gradient = self._compute_triangle_gradient(element_coords, element_solution)
            elif len(element_nodes) == 4:  # å››è¾¹å½¢
                gradient = self._compute_quadrilateral_gradient(element_coords, element_solution)
            else:
                continue
            
            # å°†æ¢¯åº¦åˆ†é…åˆ°èŠ‚ç‚¹
            for i, node_id in enumerate(element_nodes):
                recovered_gradient[node_id] += gradient
                node_weights[node_id] += 1
        
        # å¹³å‡åŒ–
        for i in range(len(nodes)):
            if node_weights[i] > 0:
                recovered_gradient[i] /= node_weights[i]
        
        return recovered_gradient
    
    def _compute_triangle_gradient(self, coords: np.ndarray, solution: np.ndarray) -> np.ndarray:
        """è®¡ç®—ä¸‰è§’å½¢å•å…ƒçš„æ¢¯åº¦"""
        # ä½¿ç”¨æœ‰é™å·®åˆ†è®¡ç®—æ¢¯åº¦
        x1, y1 = coords[0]
        x2, y2 = coords[1]
        x3, y3 = coords[2]
        
        # è®¡ç®—é¢ç§¯
        area = 0.5 * abs((x2 - x1) * (y3 - y1) - (x3 - x1) * (y2 - y1))
        
        if area < 1e-12:
            return np.zeros(2)
        
        # è®¡ç®—æ¢¯åº¦
        dx = (solution[1] - solution[0]) * (y3 - y1) - (solution[2] - solution[0]) * (y2 - y1)
        dy = (solution[2] - solution[0]) * (x2 - x1) - (solution[1] - solution[0]) * (x3 - x1)
        
        gradient = np.array([dx, dy]) / (2 * area)
        return gradient
    
    def _compute_quadrilateral_gradient(self, coords: np.ndarray, solution: np.ndarray) -> np.ndarray:
        """è®¡ç®—å››è¾¹å½¢å•å…ƒçš„æ¢¯åº¦"""
        # ç®€åŒ–ä¸ºä¸¤ä¸ªä¸‰è§’å½¢çš„ç»„åˆ
        # è¿™é‡Œå¯ä»¥å®ç°æ›´ç²¾ç¡®çš„å››è¾¹å½¢æ¢¯åº¦è®¡ç®—
        return np.zeros(2)
    
    def compute_error(self, solution: np.ndarray, mesh_data: Dict) -> List[ErrorIndicator]:
        """è®¡ç®—æ¢å¤è¯¯å·®"""
        # è®¡ç®—æ•°å€¼æ¢¯åº¦
        numerical_gradient = self._compute_numerical_gradient(solution, mesh_data)
        
        # è®¡ç®—æ¢å¤æ¢¯åº¦
        recovered_gradient = self.compute_recovered_gradient(solution, mesh_data)
        
        # è®¡ç®—è¯¯å·®
        elements = mesh_data.get('elements', [])
        error_indicators = []
        
        for i, element in enumerate(elements):
            element_nodes = element['nodes']
            
            # è®¡ç®—å•å…ƒå†…çš„æ¢¯åº¦è¯¯å·®
            element_numerical = numerical_gradient[element_nodes]
            element_recovered = recovered_gradient[element_nodes]
            
            # è®¡ç®—è¯¯å·®
            error = element_recovered - element_numerical
            error_value = np.sqrt(np.mean(error ** 2))
            
            indicator = ErrorIndicator(
                element_id=i,
                error_value=error_value,
                error_type='recovery',
                refinement_flag=error_value > self.tolerance
            )
            error_indicators.append(indicator)
        
        self.error_indicators = error_indicators
        return error_indicators
    
    def _compute_numerical_gradient(self, solution: np.ndarray, mesh_data: Dict) -> np.ndarray:
        """è®¡ç®—æ•°å€¼æ¢¯åº¦"""
        # ç®€åŒ–å®ç°ï¼šä½¿ç”¨æœ‰é™å·®åˆ†
        if solution.ndim == 1:
            return np.gradient(solution)
        else:
            gradient = np.zeros((len(solution), solution.ndim))
            for i in range(solution.ndim):
                gradient[:, i] = np.gradient(solution, axis=i)
            return gradient
    
    def compute_global_error(self, error_indicators: List[ErrorIndicator]) -> float:
        """è®¡ç®—å…¨å±€è¯¯å·®"""
        if not error_indicators:
            return 0.0
        
        error_values = [indicator.error_value for indicator in error_indicators]
        return np.sqrt(np.sum(np.array(error_values) ** 2))


class GradientErrorEstimator(BaseErrorEstimator):
    """æ¢¯åº¦è¯¯å·®ä¼°è®¡å™¨"""
    
    def __init__(self, tolerance: float = 1e-6):
        super().__init__(tolerance)
    
    def compute_error(self, solution: np.ndarray, mesh_data: Dict) -> List[ErrorIndicator]:
        """è®¡ç®—æ¢¯åº¦è¯¯å·®"""
        # è®¡ç®—æ¢¯åº¦
        gradient = self._compute_gradient(solution, mesh_data)
        
        # è®¡ç®—æ¯ä¸ªå•å…ƒçš„æ¢¯åº¦è¯¯å·®
        elements = mesh_data.get('elements', [])
        error_indicators = []
        
        for i, element in enumerate(elements):
            element_nodes = element['nodes']
            element_gradient = gradient[element_nodes]
            
            # è®¡ç®—æ¢¯åº¦çš„å˜åŒ–ç‡
            gradient_variation = np.std(element_gradient, axis=0)
            error_value = np.sqrt(np.sum(gradient_variation ** 2))
            
            indicator = ErrorIndicator(
                element_id=i,
                error_value=error_value,
                error_type='gradient',
                refinement_flag=error_value > self.tolerance
            )
            error_indicators.append(indicator)
        
        self.error_indicators = error_indicators
        return error_indicators
    
    def _compute_gradient(self, solution: np.ndarray, mesh_data: Dict) -> np.ndarray:
        """è®¡ç®—æ¢¯åº¦"""
        # ä½¿ç”¨æœ‰é™å·®åˆ†è®¡ç®—æ¢¯åº¦
        if solution.ndim == 1:
            return np.gradient(solution).reshape(-1, 1)
        else:
            gradient = np.zeros((len(solution), solution.ndim))
            for i in range(solution.ndim):
                gradient[:, i] = np.gradient(solution, axis=i)
            return gradient
    
    def compute_global_error(self, error_indicators: List[ErrorIndicator]) -> float:
        """è®¡ç®—å…¨å±€è¯¯å·®"""
        if not error_indicators:
            return 0.0
        
        error_values = [indicator.error_value for indicator in error_indicators]
        return np.sqrt(np.sum(np.array(error_values) ** 2))


class AdaptiveErrorEstimator(BaseErrorEstimator):
    """è‡ªé€‚åº”è¯¯å·®ä¼°è®¡å™¨ï¼ˆç»„åˆå¤šç§æ–¹æ³•ï¼‰"""
    
    def __init__(self, tolerance: float = 1e-6, weights: Dict[str, float] = None):
        super().__init__(tolerance)
        self.weights = weights or {
            'residual': 0.4,
            'recovery': 0.4,
            'gradient': 0.2
        }
        
        # åˆå§‹åŒ–å­ä¼°è®¡å™¨
        self.residual_estimator = ResidualErrorEstimator(tolerance)
        self.recovery_estimator = RecoveryErrorEstimator(tolerance)
        self.gradient_estimator = GradientErrorEstimator(tolerance)
    
    def compute_error(self, solution: np.ndarray, mesh_data: Dict) -> List[ErrorIndicator]:
        """è®¡ç®—ç»„åˆè¯¯å·®"""
        # è®¡ç®—å„ç§è¯¯å·®
        residual_indicators = self.residual_estimator.compute_error(solution, mesh_data)
        recovery_indicators = self.recovery_estimator.compute_error(solution, mesh_data)
        gradient_indicators = self.gradient_estimator.compute_error(solution, mesh_data)
        
        # ç»„åˆè¯¯å·®
        combined_indicators = []
        n_elements = len(residual_indicators)
        
        for i in range(n_elements):
            # åŠ æƒç»„åˆ
            combined_error = (
                self.weights['residual'] * residual_indicators[i].error_value +
                self.weights['recovery'] * recovery_indicators[i].error_value +
                self.weights['gradient'] * gradient_indicators[i].error_value
            )
            
            indicator = ErrorIndicator(
                element_id=i,
                error_value=combined_error,
                error_type='adaptive',
                refinement_flag=combined_error > self.tolerance
            )
            combined_indicators.append(indicator)
        
        self.error_indicators = combined_indicators
        return combined_indicators
    
    def compute_global_error(self, error_indicators: List[ErrorIndicator]) -> float:
        """è®¡ç®—å…¨å±€è¯¯å·®"""
        if not error_indicators:
            return 0.0
        
        error_values = [indicator.error_value for indicator in error_indicators]
        return np.sqrt(np.sum(np.array(error_values) ** 2))


# å·¥å‚å‡½æ•°
def create_error_estimator(estimator_type: str = 'adaptive', **kwargs) -> BaseErrorEstimator:
    """åˆ›å»ºè¯¯å·®ä¼°è®¡å™¨"""
    if estimator_type == 'residual':
        return ResidualErrorEstimator(**kwargs)
    elif estimator_type == 'recovery':
        return RecoveryErrorEstimator(**kwargs)
    elif estimator_type == 'gradient':
        return GradientErrorEstimator(**kwargs)
    elif estimator_type == 'adaptive':
        return AdaptiveErrorEstimator(**kwargs)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¯¯å·®ä¼°è®¡å™¨ç±»å‹: {estimator_type}")


def demo_error_estimation():
    """æ¼”ç¤ºè¯¯å·®ä¼°è®¡åŠŸèƒ½ - ä¼˜åŒ–ç‰ˆæœ¬"""
    print("ğŸ“Š è¯¯å·®ä¼°è®¡æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    n_elements = 100
    solution = np.random.rand(n_elements)
    mesh_data = {
        'elements': [{'nodes': [i, i+1]} for i in range(n_elements-1)],
        'nodes': [[i, 0] for i in range(n_elements)],
        'element_types': ['line'] * (n_elements-1)
    }
    problem_data = {
        'material_properties': {'E': 1.0, 'nu': 0.3},
        'boundary_conditions': {'dirichlet': [0, n_elements-1]}
    }
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„è¯¯å·®ä¼°è®¡å™¨
    estimators = {
        'residual_energy': ResidualErrorEstimator(tolerance=1e-3),
        'residual_l2': ResidualErrorEstimator(tolerance=1e-3),
        'recovery_spr': RecoveryErrorEstimator(tolerance=1e-3),
        'adaptive': AdaptiveErrorEstimator(tolerance=1e-3, weights={'residual': 0.4, 'recovery': 0.4, 'gradient': 0.2}),
        'gradient': GradientErrorEstimator(tolerance=1e-3)
    }
    
    for name, estimator in estimators.items():
        print(f"\nğŸ” æµ‹è¯• {name} è¯¯å·®ä¼°è®¡å™¨...")
        
        try:
            error_indicators = estimator.compute_error(solution, mesh_data)
            global_error = estimator.compute_global_error(error_indicators)
            
            print(f"   è®¡ç®—æ—¶é—´: {estimator.computation_time:.4f} ç§’")
            print(f"   å¹³å‡è¯¯å·®: {estimator.error_history[-1]:.6f}")
            print(f"   å…¨å±€è¯¯å·®: {global_error:.6f}")
            print(f"   éœ€è¦ç»†åŒ–çš„å•å…ƒæ•°: {np.sum([i.refinement_flag for i in error_indicators])}")
            
        except Exception as e:
            print(f"   âŒ è¯¯å·®ä¼°è®¡å¤±è´¥: {e}")
    
    print("\nâœ… è¯¯å·®ä¼°è®¡æ¼”ç¤ºå®Œæˆ!")


if __name__ == "__main__":
    demo_error_estimation() 