"""
æœºå™¨å­¦ä¹ ä¼˜åŒ–æ¨¡å— - æä¾›ç¥ç»ç½‘ç»œæ±‚è§£å™¨å’Œä»£ç†æ¨¡å‹
"""

import numpy as np
import time
from typing import Dict, List, Tuple, Optional, Callable, Union
import warnings

# æ·±åº¦å­¦ä¹ ç›¸å…³ä¾èµ–
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    import torch.nn.functional as F
    from torch.utils.data import DataLoader, TensorDataset
    HAS_PYTORCH = True
except ImportError:
    HAS_PYTORCH = False
    torch = None
    nn = None
    optim = None
    warnings.warn("PyTorch not available. Deep learning features will be limited.")

try:
    import sklearn
    from sklearn.gaussian_process import GaussianProcessRegressor
    from sklearn.gaussian_process.kernels import RBF, ConstantKernel
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import train_test_split
    HAS_SKLEARN = True
except ImportError:
    HAS_SKLEARN = False
    GaussianProcessRegressor = None
    warnings.warn("scikit-learn not available. Surrogate models will be limited.")


class NeuralNetworkSolver(nn.Module):
    """ç¥ç»ç½‘ç»œæ±‚è§£å™¨ - åŸºç¡€ç‰ˆæœ¬"""
    
    def __init__(self, input_dim: int, hidden_dims: list, output_dim: int, 
                 activation: str = 'relu', dropout: float = 0.1):
        super(NeuralNetworkSolver, self).__init__()
        
        if not HAS_PYTORCH:
            raise ImportError("éœ€è¦å®‰è£…PyTorchæ¥ä½¿ç”¨ç¥ç»ç½‘ç»œæ±‚è§£å™¨")
        
        self.input_dim = input_dim
        self.hidden_dims = hidden_dims
        self.output_dim = output_dim
        self.activation = activation
        self.dropout = dropout
        
        # æ„å»ºç½‘ç»œå±‚
        layers = []
        prev_dim = input_dim
        
        for hidden_dim in hidden_dims:
            layers.append(nn.Linear(prev_dim, hidden_dim))
            if activation == 'relu':
                layers.append(nn.ReLU())
            elif activation == 'tanh':
                layers.append(nn.Tanh())
            elif activation == 'sigmoid':
                layers.append(nn.Sigmoid())
            else:
                layers.append(nn.ReLU())
            
            if dropout > 0:
                layers.append(nn.Dropout(dropout))
            prev_dim = hidden_dim
        
        layers.append(nn.Linear(prev_dim, output_dim))
        self.network = nn.Sequential(*layers)
        
        self.optimizer = None
        self.criterion = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.to(self.device)
        
        print(f"ğŸ”„ ç¥ç»ç½‘ç»œæ±‚è§£å™¨åˆå§‹åŒ–å®Œæˆ - è®¾å¤‡: {self.device}")
    
    def forward(self, x):
        return self.network(x)
    
    def setup_training(self, learning_rate: float = 0.001, weight_decay: float = 1e-5):
        """è®¾ç½®è®­ç»ƒå‚æ•°"""
        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate, weight_decay=weight_decay)
        self.criterion = nn.MSELoss()
    
    def train_model(self, X: np.ndarray, y: np.ndarray, epochs: int = 100, 
                   batch_size: int = 32, validation_split: float = 0.2) -> dict:
        """è®­ç»ƒæ¨¡å‹"""
        if self.optimizer is None:
            self.setup_training()
        
        # æ•°æ®é¢„å¤„ç†
        X_tensor = torch.FloatTensor(X).to(self.device)
        y_tensor = torch.FloatTensor(y).to(self.device)
        
        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        if validation_split > 0:
            X_train, X_val, y_train, y_val = train_test_split(
                X_tensor, y_tensor, test_size=validation_split, random_state=42
            )
        else:
            X_train, X_val, y_train, y_val = X_tensor, None, y_tensor, None
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_dataset = TensorDataset(X_train, y_train)
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        
        history = {'train_loss': [], 'val_loss': [], 'train_time': 0.0}
        start_time = time.time()
        
        for epoch in range(epochs):
            self.train()
            epoch_loss = 0.0
            
            for batch_X, batch_y in train_loader:
                self.optimizer.zero_grad()
                outputs = self(batch_X)
                loss = self.criterion(outputs, batch_y)
                loss.backward()
                self.optimizer.step()
                epoch_loss += loss.item()
            
            # è®¡ç®—å¹³å‡æŸå¤±
            avg_train_loss = epoch_loss / len(train_loader)
            history['train_loss'].append(avg_train_loss)
            
            # éªŒè¯æŸå¤±
            if X_val is not None:
                self.eval()
                with torch.no_grad():
                    val_outputs = self(X_val)
                    val_loss = self.criterion(val_outputs, y_val)
                    history['val_loss'].append(val_loss.item())
            
            if (epoch + 1) % 10 == 0:
                val_info = f", val_loss={history['val_loss'][-1]:.6f}" if X_val is not None else ""
                print(f"   Epoch {epoch+1}/{epochs}: train_loss={avg_train_loss:.6f}{val_info}")
        
        history['train_time'] = time.time() - start_time
        return history
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """é¢„æµ‹"""
        self.eval()
        with torch.no_grad():
            X_tensor = torch.FloatTensor(X).to(self.device)
            outputs = self(X_tensor)
            return outputs.cpu().numpy()
    
    def save_model(self, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        torch.save(self.state_dict(), filepath)
        print(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜: {filepath}")
    
    def load_model(self, filepath: str):
        """åŠ è½½æ¨¡å‹"""
        self.load_state_dict(torch.load(filepath, map_location=self.device))
        print(f"ğŸ“ æ¨¡å‹å·²åŠ è½½: {filepath}")


class UNetSolver(nn.Module):
    """U-Netæ±‚è§£å™¨ - ç”¨äºç©ºé—´åœºé¢„æµ‹"""
    
    def __init__(self, input_channels: int, output_channels: int, 
                 initial_features: int = 64, depth: int = 4):
        super(UNetSolver, self).__init__()
        
        if not HAS_PYTORCH:
            raise ImportError("éœ€è¦å®‰è£…PyTorchæ¥ä½¿ç”¨U-Netæ±‚è§£å™¨")
        
        self.input_channels = input_channels
        self.output_channels = output_channels
        self.initial_features = initial_features
        self.depth = depth
        
        # ç¼–ç å™¨
        self.encoder = nn.ModuleList()
        in_channels = input_channels
        
        for i in range(depth):
            out_channels = initial_features * (2 ** i)
            self.encoder.append(
                nn.Sequential(
                    nn.Conv2d(in_channels, out_channels, 3, padding=1),
                    nn.ReLU(inplace=True),
                    nn.Conv2d(out_channels, out_channels, 3, padding=1),
                    nn.ReLU(inplace=True)
                )
            )
            in_channels = out_channels
        
        # è§£ç å™¨
        self.decoder = nn.ModuleList()
        for i in range(depth - 1, -1, -1):
            out_channels = initial_features * (2 ** i)
            self.decoder.append(
                nn.Sequential(
                    nn.ConvTranspose2d(in_channels * 2, out_channels, 2, stride=2),
                    nn.Conv2d(out_channels, out_channels, 3, padding=1),
                    nn.ReLU(inplace=True),
                    nn.Conv2d(out_channels, out_channels, 3, padding=1),
                    nn.ReLU(inplace=True)
                )
            )
            in_channels = out_channels
        
        # æœ€ç»ˆè¾“å‡ºå±‚
        self.final_conv = nn.Conv2d(initial_features, output_channels, 1)
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.to(self.device)
        
        print(f"ğŸ”„ U-Netæ±‚è§£å™¨åˆå§‹åŒ–å®Œæˆ - è®¾å¤‡: {self.device}")
    
    def forward(self, x):
        # ç¼–ç 
        encoder_outputs = []
        for encoder_layer in self.encoder:
            x = encoder_layer(x)
            encoder_outputs.append(x)
            x = F.max_pool2d(x, 2)
        
        # è§£ç 
        for i, decoder_layer in enumerate(self.decoder):
            x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)
            x = torch.cat([x, encoder_outputs[-(i+1)]], dim=1)
            x = decoder_layer(x)
        
        return self.final_conv(x)
    
    def setup_training(self, learning_rate: float = 0.001):
        """è®¾ç½®è®­ç»ƒå‚æ•°"""
        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)
        self.criterion = nn.MSELoss()
    
    def train_model(self, X: np.ndarray, y: np.ndarray, epochs: int = 100, 
                   batch_size: int = 8) -> dict:
        """è®­ç»ƒæ¨¡å‹"""
        if self.optimizer is None:
            self.setup_training()
        
        # æ•°æ®é¢„å¤„ç† - ç¡®ä¿æ˜¯4Då¼ é‡ (batch, channels, height, width)
        if X.ndim == 3:
            X = X[:, np.newaxis, :, :]
        if y.ndim == 3:
            y = y[:, np.newaxis, :, :]
        
        X_tensor = torch.FloatTensor(X).to(self.device)
        y_tensor = torch.FloatTensor(y).to(self.device)
        
        train_dataset = TensorDataset(X_tensor, y_tensor)
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        
        history = {'train_loss': [], 'train_time': 0.0}
        start_time = time.time()
        
        for epoch in range(epochs):
            self.train()
            epoch_loss = 0.0
            
            for batch_X, batch_y in train_loader:
                self.optimizer.zero_grad()
                outputs = self(batch_X)
                loss = self.criterion(outputs, batch_y)
                loss.backward()
                self.optimizer.step()
                epoch_loss += loss.item()
            
            avg_loss = epoch_loss / len(train_loader)
            history['train_loss'].append(avg_loss)
            
            if (epoch + 1) % 10 == 0:
                print(f"   Epoch {epoch+1}/{epochs}: loss={avg_loss:.6f}")
        
        history['train_time'] = time.time() - start_time
        return history
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """é¢„æµ‹"""
        self.eval()
        with torch.no_grad():
            if X.ndim == 3:
                X = X[:, np.newaxis, :, :]
            X_tensor = torch.FloatTensor(X).to(self.device)
            outputs = self(X_tensor)
            return outputs.cpu().numpy()


class PINNSolver(nn.Module):
    """ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼ˆPINNï¼‰æ±‚è§£å™¨"""
    
    def __init__(self, input_dim: int, hidden_dims: list, output_dim: int,
                 physics_equations: List[Callable] = None):
        super(PINNSolver, self).__init__()
        
        if not HAS_PYTORCH:
            raise ImportError("éœ€è¦å®‰è£…PyTorchæ¥ä½¿ç”¨PINNæ±‚è§£å™¨")
        
        self.input_dim = input_dim
        self.hidden_dims = hidden_dims
        self.output_dim = output_dim
        self.physics_equations = physics_equations or []
        
        # æ„å»ºç½‘ç»œ
        layers = []
        prev_dim = input_dim
        
        for hidden_dim in hidden_dims:
            layers.append(nn.Linear(prev_dim, hidden_dim))
            layers.append(nn.Tanh())  # PINNé€šå¸¸ä½¿ç”¨Tanhæ¿€æ´»å‡½æ•°
            prev_dim = hidden_dim
        
        layers.append(nn.Linear(prev_dim, output_dim))
        self.network = nn.Sequential(*layers)
        
        self.optimizer = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.to(self.device)
        
        print(f"ğŸ”„ PINNæ±‚è§£å™¨åˆå§‹åŒ–å®Œæˆ - è®¾å¤‡: {self.device}")
    
    def forward(self, x):
        return self.network(x)
    
    def setup_training(self, learning_rate: float = 0.001):
        """è®¾ç½®è®­ç»ƒå‚æ•°"""
        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)
    
    def compute_physics_loss(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—ç‰©ç†çº¦æŸæŸå¤±"""
        if not self.physics_equations:
            return torch.tensor(0.0, device=self.device)
        
        total_loss = torch.tensor(0.0, device=self.device)
        
        for equation in self.physics_equations:
            # è®¡ç®—ç‰©ç†æ–¹ç¨‹çš„æ®‹å·®
            residual = equation(x, y)
            total_loss += torch.mean(residual ** 2)
        
        return total_loss
    
    def train_model(self, X: np.ndarray, y: np.ndarray, 
                   physics_points: np.ndarray = None,
                   epochs: int = 1000, 
                   physics_weight: float = 1.0) -> dict:
        """è®­ç»ƒPINNæ¨¡å‹"""
        if self.optimizer is None:
            self.setup_training()
        
        X_tensor = torch.FloatTensor(X).to(self.device)
        y_tensor = torch.FloatTensor(y).to(self.device)
        
        if physics_points is not None:
            physics_tensor = torch.FloatTensor(physics_points).to(self.device)
        
        history = {'total_loss': [], 'data_loss': [], 'physics_loss': [], 'train_time': 0.0}
        start_time = time.time()
        
        for epoch in range(epochs):
            self.train()
            self.optimizer.zero_grad()
            
            # æ•°æ®æŸå¤±
            outputs = self(X_tensor)
            data_loss = F.mse_loss(outputs, y_tensor)
            
            # ç‰©ç†æŸå¤±
            if physics_points is not None and self.physics_equations:
                physics_outputs = self(physics_tensor)
                physics_loss = self.compute_physics_loss(physics_tensor, physics_outputs)
            else:
                physics_loss = torch.tensor(0.0, device=self.device)
            
            # æ€»æŸå¤±
            total_loss = data_loss + physics_weight * physics_loss
            
            total_loss.backward()
            self.optimizer.step()
            
            history['total_loss'].append(total_loss.item())
            history['data_loss'].append(data_loss.item())
            history['physics_loss'].append(physics_loss.item())
            
            if (epoch + 1) % 100 == 0:
                print(f"   Epoch {epoch+1}/{epochs}: total_loss={total_loss.item():.6f}, "
                      f"data_loss={data_loss.item():.6f}, physics_loss={physics_loss.item():.6f}")
        
        history['train_time'] = time.time() - start_time
        return history
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """é¢„æµ‹"""
        self.eval()
        with torch.no_grad():
            X_tensor = torch.FloatTensor(X).to(self.device)
            outputs = self(X_tensor)
            return outputs.cpu().numpy()


class SurrogateModel:
    """ä»£ç†æ¨¡å‹ - ç”¨äºå¿«é€Ÿé¢„æµ‹"""
    
    def __init__(self, model_type: str = 'gaussian_process'):
        self.model_type = model_type
        self.model = None
        self.scaler_X = StandardScaler()
        self.scaler_y = StandardScaler()
        self.is_trained = False
        
        if model_type == 'gaussian_process' and not HAS_SKLEARN:
            raise ImportError("éœ€è¦å®‰è£…scikit-learnæ¥ä½¿ç”¨é«˜æ–¯è¿‡ç¨‹å›å½’")
    
    def train(self, X: np.ndarray, y: np.ndarray, **kwargs) -> dict:
        """è®­ç»ƒä»£ç†æ¨¡å‹"""
        start_time = time.time()
        
        # æ•°æ®æ ‡å‡†åŒ–
        X_scaled = self.scaler_X.fit_transform(X)
        y_scaled = self.scaler_y.fit_transform(y.reshape(-1, 1)).flatten()
        
        if self.model_type == 'gaussian_process':
            # é«˜æ–¯è¿‡ç¨‹å›å½’
            kernel = RBF(length_scale=1.0) + ConstantKernel()
            self.model = GaussianProcessRegressor(kernel=kernel, random_state=42)
            self.model.fit(X_scaled, y_scaled)
        
        self.is_trained = True
        training_time = time.time() - start_time
        
        return {'training_time': training_time, 'model_type': self.model_type}
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """é¢„æµ‹"""
        if not self.is_trained:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")
        
        X_scaled = self.scaler_X.transform(X)
        
        if self.model_type == 'gaussian_process':
            y_pred_scaled, std = self.model.predict(X_scaled, return_std=True)
            y_pred = self.scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
            return y_pred, std
        
        return self.scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()


class MLAccelerator:
    """æœºå™¨å­¦ä¹ åŠ é€Ÿå™¨ - ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, use_gpu: bool = True):
        self.use_gpu = use_gpu and HAS_PYTORCH
        self.models = {}
        self.surrogate_models = {}
        self.performance_stats = {
            'total_training_time': 0.0,
            'total_prediction_time': 0.0,
            'models_created': 0,
            'predictions_made': 0
        }
        
        print(f"ğŸ”„ MLåŠ é€Ÿå™¨åˆå§‹åŒ–å®Œæˆ - GPU: {self.use_gpu}")
    
    def create_neural_solver(self, name: str, input_dim: int, hidden_dims: list, 
                           output_dim: int, solver_type: str = 'basic') -> NeuralNetworkSolver:
        """åˆ›å»ºç¥ç»ç½‘ç»œæ±‚è§£å™¨"""
        if solver_type == 'basic':
            solver = NeuralNetworkSolver(input_dim, hidden_dims, output_dim)
        elif solver_type == 'unet':
            solver = UNetSolver(input_dim, output_dim)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ±‚è§£å™¨ç±»å‹: {solver_type}")
        
        self.models[name] = solver
        self.performance_stats['models_created'] += 1
        
        print(f"âœ… ç¥ç»ç½‘ç»œæ±‚è§£å™¨ '{name}' åˆ›å»ºå®Œæˆ")
        return solver
    
    def create_pinn_solver(self, name: str, input_dim: int, hidden_dims: list, 
                          output_dim: int, physics_equations: List[Callable] = None) -> PINNSolver:
        """åˆ›å»ºPINNæ±‚è§£å™¨"""
        solver = PINNSolver(input_dim, hidden_dims, output_dim, physics_equations)
        self.models[name] = solver
        self.performance_stats['models_created'] += 1
        
        print(f"âœ… PINNæ±‚è§£å™¨ '{name}' åˆ›å»ºå®Œæˆ")
        return solver
    
    def create_surrogate_model(self, name: str, model_type: str = 'gaussian_process') -> SurrogateModel:
        """åˆ›å»ºä»£ç†æ¨¡å‹"""
        surrogate = SurrogateModel(model_type)
        self.surrogate_models[name] = surrogate
        self.performance_stats['models_created'] += 1
        
        print(f"âœ… ä»£ç†æ¨¡å‹ '{name}' åˆ›å»ºå®Œæˆ")
        return surrogate
    
    def train_model(self, name: str, X: np.ndarray, y: np.ndarray, **kwargs) -> dict:
        """è®­ç»ƒæ¨¡å‹"""
        if name in self.models:
            model = self.models[name]
            if isinstance(model, PINNSolver):
                physics_points = kwargs.get('physics_points', None)
                physics_weight = kwargs.get('physics_weight', 1.0)
                result = model.train_model(X, y, physics_points, **kwargs)
            else:
                result = model.train_model(X, y, **kwargs)
        elif name in self.surrogate_models:
            model = self.surrogate_models[name]
            result = model.train(X, y, **kwargs)
        else:
            raise ValueError(f"æ¨¡å‹ '{name}' ä¸å­˜åœ¨")
        
        self.performance_stats['total_training_time'] += result.get('training_time', 0.0)
        return result
    
    def predict(self, name: str, X: np.ndarray) -> np.ndarray:
        """é¢„æµ‹"""
        start_time = time.time()
        
        if name in self.models:
            result = self.models[name].predict(X)
        elif name in self.surrogate_models:
            result = self.surrogate_models[name].predict(X)
        else:
            raise ValueError(f"æ¨¡å‹ '{name}' ä¸å­˜åœ¨")
        
        prediction_time = time.time() - start_time
        self.performance_stats['total_prediction_time'] += prediction_time
        self.performance_stats['predictions_made'] += 1
        
        return result
    
    def get_performance_stats(self) -> dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        return self.performance_stats.copy()
    
    def save_model(self, name: str, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        if name in self.models:
            self.models[name].save_model(filepath)
        else:
            raise ValueError(f"æ¨¡å‹ '{name}' ä¸å­˜åœ¨")
    
    def load_model(self, name: str, filepath: str):
        """åŠ è½½æ¨¡å‹"""
        if name in self.models:
            self.models[name].load_model(filepath)
        else:
            raise ValueError(f"æ¨¡å‹ '{name}' ä¸å­˜åœ¨")


def create_ml_accelerator(use_gpu: bool = True) -> MLAccelerator:
    """åˆ›å»ºMLåŠ é€Ÿå™¨"""
    return MLAccelerator(use_gpu=use_gpu)


def demo_ml_optimization():
    """æ¼”ç¤ºæœºå™¨å­¦ä¹ ä¼˜åŒ–åŠŸèƒ½"""
    print("ğŸ¤– æœºå™¨å­¦ä¹ ä¼˜åŒ–æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºMLåŠ é€Ÿå™¨
    accelerator = create_ml_accelerator()
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    n_samples = 1000
    input_dim = 10
    output_dim = 5
    
    X = np.random.randn(n_samples, input_dim)
    y = np.random.randn(n_samples, output_dim)
    
    print(f"ğŸ“Š æµ‹è¯•æ•°æ®: {n_samples} æ ·æœ¬, è¾“å…¥ç»´åº¦: {input_dim}, è¾“å‡ºç»´åº¦: {output_dim}")
    
    # 1. æµ‹è¯•åŸºç¡€ç¥ç»ç½‘ç»œæ±‚è§£å™¨
    print("\nğŸ”§ æµ‹è¯•åŸºç¡€ç¥ç»ç½‘ç»œæ±‚è§£å™¨...")
    try:
        neural_solver = accelerator.create_neural_solver(
            'basic_solver', input_dim, [64, 32], output_dim
        )
        neural_solver.setup_training()
        result = accelerator.train_model('basic_solver', X, y, epochs=50)
        print(f"   è®­ç»ƒæ—¶é—´: {result['train_time']:.4f} ç§’")
        
        # é¢„æµ‹
        predictions = accelerator.predict('basic_solver', X[:10])
        print(f"   é¢„æµ‹å½¢çŠ¶: {predictions.shape}")
        
    except Exception as e:
        print(f"   âŒ åŸºç¡€ç¥ç»ç½‘ç»œæ±‚è§£å™¨å¤±è´¥: {e}")
    
    # 2. æµ‹è¯•U-Netæ±‚è§£å™¨
    print("\nğŸ”§ æµ‹è¯•U-Netæ±‚è§£å™¨...")
    try:
        # ç”Ÿæˆ2Dæ•°æ®
        n_samples_2d = 100
        height, width = 32, 32
        X_2d = np.random.randn(n_samples_2d, height, width)
        y_2d = np.random.randn(n_samples_2d, height, width)
        
        unet_solver = accelerator.create_neural_solver(
            'unet_solver', 1, [64, 32], 1, solver_type='unet'
        )
        unet_solver.setup_training()
        result = accelerator.train_model('unet_solver', X_2d, y_2d, epochs=20)
        print(f"   è®­ç»ƒæ—¶é—´: {result['train_time']:.4f} ç§’")
        
    except Exception as e:
        print(f"   âŒ U-Netæ±‚è§£å™¨å¤±è´¥: {e}")
    
    # 3. æµ‹è¯•PINNæ±‚è§£å™¨
    print("\nğŸ”§ æµ‹è¯•PINNæ±‚è§£å™¨...")
    try:
        # å®šä¹‰ç®€å•çš„ç‰©ç†æ–¹ç¨‹ï¼ˆç¤ºä¾‹ï¼šçƒ­ä¼ å¯¼æ–¹ç¨‹ï¼‰
        def heat_equation(x, y):
            # ç®€åŒ–çš„çƒ­ä¼ å¯¼æ–¹ç¨‹æ®‹å·®
            return torch.mean(torch.abs(y - 0.1 * torch.sum(x, dim=1, keepdim=True)))
        
        pinn_solver = accelerator.create_pinn_solver(
            'pinn_solver', input_dim, [64, 32], output_dim, [heat_equation]
        )
        pinn_solver.setup_training()
        result = accelerator.train_model('pinn_solver', X, y, epochs=100)
        print(f"   è®­ç»ƒæ—¶é—´: {result['train_time']:.4f} ç§’")
        
    except Exception as e:
        print(f"   âŒ PINNæ±‚è§£å™¨å¤±è´¥: {e}")
    
    # 4. æµ‹è¯•ä»£ç†æ¨¡å‹
    print("\nğŸ”§ æµ‹è¯•ä»£ç†æ¨¡å‹...")
    try:
        surrogate = accelerator.create_surrogate_model('gpr_model', 'gaussian_process')
        result = accelerator.train_model('gpr_model', X, y[:, 0])  # åªé¢„æµ‹ç¬¬ä¸€ä¸ªè¾“å‡º
        print(f"   è®­ç»ƒæ—¶é—´: {result['training_time']:.4f} ç§’")
        
        # é¢„æµ‹
        predictions, std = accelerator.predict('gpr_model', X[:10])
        print(f"   é¢„æµ‹å½¢çŠ¶: {predictions.shape}, æ ‡å‡†å·®å½¢çŠ¶: {std.shape}")
        
    except Exception as e:
        print(f"   âŒ ä»£ç†æ¨¡å‹å¤±è´¥: {e}")
    
    # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
    stats = accelerator.get_performance_stats()
    print(f"\nğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
    print(f"   æ€»è®­ç»ƒæ—¶é—´: {stats['total_training_time']:.4f} ç§’")
    print(f"   æ€»é¢„æµ‹æ—¶é—´: {stats['total_prediction_time']:.4f} ç§’")
    print(f"   åˆ›å»ºçš„æ¨¡å‹æ•°: {stats['models_created']}")
    print(f"   é¢„æµ‹æ¬¡æ•°: {stats['predictions_made']}")
    
    print("\nâœ… æœºå™¨å­¦ä¹ ä¼˜åŒ–æ¼”ç¤ºå®Œæˆ!")


if __name__ == "__main__":
    demo_ml_optimization() 